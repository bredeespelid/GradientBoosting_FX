{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## GB_FX Price only Monthly"
      ],
      "metadata": {
        "id": "aNK1Z0zWRghh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HX3mkmdSRO7j"
      },
      "outputs": [],
      "source": [
        "# =========================================\n",
        "# Gradient Boosting – EUR/NOK walk-forward (monthly, levels), point forecast only\n",
        "# PARALLEL OUTER LOOP\n",
        "# - Data: GitHub CSV (semicolon-separated; decimal comma), forward-filled to daily\n",
        "# - Cut: last business day of previous month\n",
        "# - Model: GradientBoostingRegressor on daily lag features\n",
        "# - Forecast: recursive daily next-month -> aggregate to monthly mean over business days\n",
        "# - Metrics: Observations, RMSE, MAE, Directional accuracy\n",
        "# - Test: Diebold–Mariano vs Random Walk (MSE, h=1)\n",
        "# - Plot: Actual (black) vs Forecast (blue dashed), no intervals\n",
        "# =========================================\n",
        "\n",
        "!pip -q install pandas numpy scikit-learn matplotlib requests certifi joblib\n",
        "\n",
        "from __future__ import annotations\n",
        "import io, time, math\n",
        "from dataclasses import dataclass\n",
        "from typing import Optional, Tuple, Dict\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import requests, certifi\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from joblib import Parallel, delayed\n",
        "\n",
        "# -----------------------------\n",
        "# Configuration\n",
        "# -----------------------------\n",
        "@dataclass\n",
        "class Config:\n",
        "    url: str = \"https://raw.githubusercontent.com/bredeespelid/Data_MasterOppgave/refs/heads/main/EURNOK/EUR_NOK_NorgesBank.csv\"\n",
        "    m_freq: str = \"M\"                 # monthly evaluation\n",
        "    min_hist_days: int = 200          # GB needs more history than Chronos\n",
        "    max_lags: int = 20                # number of daily lags used as features\n",
        "\n",
        "    # Gradient Boosting hyperparameters (tune if needed)\n",
        "    n_estimators: int = 800\n",
        "    learning_rate: float = 0.03\n",
        "    max_depth: int = 3                # tree depth per boosting stage\n",
        "    subsample: float = 0.8            # stochastic GB\n",
        "    min_samples_leaf: int = 2\n",
        "    random_state: int = 42\n",
        "\n",
        "    retries: int = 3\n",
        "    timeout: int = 60\n",
        "    verbose: bool = True\n",
        "    fig_png: str = \"GB_Monthly.png\"\n",
        "    fig_pdf: str = \"GB_Monthly.pdf\"\n",
        "\n",
        "CFG = Config()\n",
        "\n",
        "# -----------------------------\n",
        "# Download helper\n",
        "# -----------------------------\n",
        "def download_csv_text(url: str, retries: int, timeout: int) -> str:\n",
        "    \"\"\"Download CSV with simple retry/backoff.\"\"\"\n",
        "    last_err = None\n",
        "    for k in range(1, retries + 1):\n",
        "        try:\n",
        "            r = requests.get(url, timeout=timeout, verify=certifi.where())\n",
        "            r.raise_for_status()\n",
        "            return r.text\n",
        "        except Exception as e:\n",
        "            last_err = e\n",
        "            if k < retries:\n",
        "                wait = 1.5 * k\n",
        "                print(f\"[warning] Download failed (try {k}/{retries}): {e}. Retrying in {wait:.1f}s ...\")\n",
        "                time.sleep(wait)\n",
        "    raise RuntimeError(f\"Download failed: {last_err}\")\n",
        "\n",
        "# -----------------------------\n",
        "# Data loading\n",
        "# -----------------------------\n",
        "def load_series(url: str) -> Tuple[pd.Series, pd.Series]:\n",
        "    \"\"\"\n",
        "    Load Norges Bank CSV (semicolon-separated; decimal comma) with columns TIME_PERIOD, OBS_VALUE.\n",
        "    Returns:\n",
        "      S_b: business-day (B) with ffill (used for cuts and monthly ground truth)\n",
        "      S_d: daily (D) with ffill (model inputs and daily forecasts)\n",
        "    \"\"\"\n",
        "    text = download_csv_text(url, CFG.retries, CFG.timeout)\n",
        "    raw = pd.read_csv(io.StringIO(text), sep=';', encoding='utf-8-sig', decimal=',')\n",
        "\n",
        "    df = (raw[['TIME_PERIOD', 'OBS_VALUE']]\n",
        "          .rename(columns={'OBS_VALUE': 'EUR_NOK'})\n",
        "          .assign(TIME_PERIOD=lambda x: pd.to_datetime(x['TIME_PERIOD'], errors='coerce'))\n",
        "          .dropna(subset=['TIME_PERIOD', 'EUR_NOK'])\n",
        "          .sort_values('TIME_PERIOD')\n",
        "          .set_index('TIME_PERIOD'))\n",
        "\n",
        "    # Business-day series (truth/aggregation base)\n",
        "    S_b = df['EUR_NOK'].asfreq('B').ffill().astype(float)\n",
        "    S_b.name = 'EUR_NOK'\n",
        "\n",
        "    # Daily series (model inputs / daily forecasts)\n",
        "    full_idx = pd.date_range(df.index.min(), df.index.max(), freq='D')\n",
        "    S_d = df['EUR_NOK'].reindex(full_idx).ffill().astype(float)\n",
        "    S_d.index.name = 'DATE'\n",
        "    S_d.name = 'EUR_NOK'\n",
        "    return S_b, S_d\n",
        "\n",
        "def last_trading_day(S_b: pd.Series, start: pd.Timestamp, end: pd.Timestamp) -> Optional[pd.Timestamp]:\n",
        "    \"\"\"Return the last business day in [start, end].\"\"\"\n",
        "    sl = S_b.loc[start:end]\n",
        "    return sl.index[-1] if not sl.empty else None\n",
        "\n",
        "# -----------------------------\n",
        "# Feature engineering (lags)\n",
        "# -----------------------------\n",
        "def make_lag_matrix(y: pd.Series, max_lags: int) -> Tuple[np.ndarray, np.ndarray]:\n",
        "    \"\"\"\n",
        "    Build X, y_target for one-step ahead forecasting:\n",
        "      X_t = [y_{t-1}, ..., y_{t-max_lags}]\n",
        "      y_target = y_t\n",
        "    \"\"\"\n",
        "    df = pd.DataFrame({'y': y})\n",
        "    for k in range(1, max_lags + 1):\n",
        "        df[f'lag{k}'] = df['y'].shift(k)\n",
        "    df = df.dropna()\n",
        "    X = df[[f'lag{k}' for k in range(1, max_lags + 1)]].values\n",
        "    y_target = df['y'].values\n",
        "    return X, y_target\n",
        "\n",
        "# -----------------------------\n",
        "# Gradient Boosting one-step model\n",
        "# -----------------------------\n",
        "def fit_gb_one_step(y_hist_daily: pd.Series) -> GradientBoostingRegressor:\n",
        "    \"\"\"\n",
        "    Fit Gradient Boosting for one-step ahead daily prediction.\n",
        "    GradientBoostingRegressor is single-threaded by design,\n",
        "    which is good for outer-loop parallelization.\n",
        "    \"\"\"\n",
        "    X, y_target = make_lag_matrix(y_hist_daily, CFG.max_lags)\n",
        "    model = GradientBoostingRegressor(\n",
        "        n_estimators=CFG.n_estimators,\n",
        "        learning_rate=CFG.learning_rate,\n",
        "        max_depth=CFG.max_depth,\n",
        "        subsample=CFG.subsample,\n",
        "        min_samples_leaf=CFG.min_samples_leaf,\n",
        "        random_state=CFG.random_state,\n",
        "    )\n",
        "    model.fit(X, y_target)\n",
        "    return model\n",
        "\n",
        "def recursive_daily_forecast(model: GradientBoostingRegressor, y_hist_daily: pd.Series, H: int) -> pd.Series:\n",
        "    \"\"\"\n",
        "    Produce H daily forecasts recursively:\n",
        "      - start from last max_lags observed values\n",
        "      - each step uses previous predicted value as newest lag\n",
        "    \"\"\"\n",
        "    hist = y_hist_daily.values.tolist()\n",
        "    preds = []\n",
        "    for _ in range(H):\n",
        "        if len(hist) < CFG.max_lags:\n",
        "            raise ValueError(\"Not enough history for lag features.\")\n",
        "        x = np.array(hist[-CFG.max_lags:][::-1], dtype=float).reshape(1, -1)\n",
        "        yhat = float(model.predict(x)[0])\n",
        "        preds.append(yhat)\n",
        "        hist.append(yhat)\n",
        "    return pd.Series(preds)\n",
        "\n",
        "# -----------------------------\n",
        "# Monthly walk-forward using GB (PARALLEL outer loop)\n",
        "# -----------------------------\n",
        "def walk_forward_gb_monthly_parallel(S_b: pd.Series, S_d: pd.Series, n_jobs_outer: int = -1) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    For each calendar month m:\n",
        "      - cut at last business day of previous month\n",
        "      - fit GB on daily history up to cut\n",
        "      - recursively forecast full calendar month at daily frequency\n",
        "      - aggregate to business-day monthly mean and compare to truth\n",
        "\n",
        "    Outer loop parallelization:\n",
        "      - each month is independent and computed in parallel.\n",
        "    \"\"\"\n",
        "    first_m = pd.Period(S_b.index.min(), freq=CFG.m_freq)\n",
        "    last_m  = pd.Period(S_b.index.max(),  freq=CFG.m_freq)\n",
        "    months = pd.period_range(first_m, last_m, freq=CFG.m_freq)\n",
        "\n",
        "    def _process_one_month(m: pd.Period):\n",
        "        prev_m = m - 1\n",
        "        m_start, m_end = m.start_time, m.end_time\n",
        "        prev_start, prev_end = prev_m.start_time, prev_m.end_time\n",
        "\n",
        "        cut = last_trading_day(S_b, prev_start, prev_end)\n",
        "        if cut is None:\n",
        "            return (str(m), None, \"no_cut_in_prev_month\")\n",
        "\n",
        "        hist_d = S_d.loc[:cut]\n",
        "        if hist_d.size < CFG.min_hist_days:\n",
        "            return (str(m), None, f\"hist<{CFG.min_hist_days}\")\n",
        "\n",
        "        # Business days inside target month\n",
        "        idx_m_b = S_b.index[(S_b.index >= m_start) & (S_b.index <= m_end)]\n",
        "        if idx_m_b.size < 1:\n",
        "            return (str(m), None, \"no_bdays_in_month\")\n",
        "        y_true = float(S_b.loc[idx_m_b].mean())\n",
        "\n",
        "        # Horizon = full calendar month length (inclusive)\n",
        "        H = (m_end.date() - m_start.date()).days + 1\n",
        "        if H <= 0:\n",
        "            return (str(m), None, f\"horizon_invalid(H={H})\")\n",
        "\n",
        "        # Fit model on daily history up to cut\n",
        "        model = fit_gb_one_step(hist_d)\n",
        "\n",
        "        # Recursive daily forecast for next month\n",
        "        pf = recursive_daily_forecast(model, hist_d, H)\n",
        "\n",
        "        # Index daily forecast from cut+1 over H calendar days\n",
        "        f_idx = pd.date_range(cut + pd.Timedelta(days=1), periods=H, freq='D')\n",
        "        pred_daily = pd.Series(pf.values, index=f_idx, name='point')\n",
        "\n",
        "        # Aggregate forecast to business-day mean over the month\n",
        "        pred_b = pred_daily.reindex(idx_m_b, method=None)\n",
        "        if pred_b.isna().all():\n",
        "            return (str(m), None, \"no_overlap_pred_B_days\")\n",
        "        y_pred = float(pred_b.dropna().mean())\n",
        "\n",
        "        row = {\"month\": m, \"cut\": cut, \"y_true\": y_true, \"y_pred\": y_pred}\n",
        "        return (str(m), row, None)\n",
        "\n",
        "    results = Parallel(n_jobs=n_jobs_outer, backend=\"loky\")(\n",
        "        delayed(_process_one_month)(m) for m in months\n",
        "    )\n",
        "\n",
        "    rows: Dict[str, dict] = {}\n",
        "    dropped: Dict[str, str] = {}\n",
        "\n",
        "    for key, row, reason in results:\n",
        "        if row is not None:\n",
        "            rows[key] = row\n",
        "        else:\n",
        "            dropped[key] = reason or \"unknown\"\n",
        "\n",
        "    df = pd.DataFrame.from_dict(rows, orient='index')\n",
        "    if not df.empty:\n",
        "        df = df.set_index(\"month\").sort_index()\n",
        "\n",
        "    if CFG.verbose and dropped:\n",
        "        miss = [str(m) for m in months if str(m) not in rows]\n",
        "        if miss:\n",
        "            print(\"\\nDropped months and reasons:\")\n",
        "            for mm in miss:\n",
        "                print(f\"  {mm}: {dropped.get(mm, 'unknown')}\")\n",
        "\n",
        "    return df\n",
        "\n",
        "# -----------------------------\n",
        "# Evaluation (level + direction)\n",
        "# -----------------------------\n",
        "def evaluate(eval_df: pd.DataFrame) -> pd.DataFrame:\n",
        "    \"\"\"Compute level errors and directional accuracy.\"\"\"\n",
        "    df = eval_df.copy()\n",
        "    df[\"err\"] = df[\"y_true\"] - df[\"y_pred\"]\n",
        "    core = df.dropna(subset=[\"y_true\", \"y_pred\"]).copy()\n",
        "\n",
        "    n_obs = int(len(core))\n",
        "    rmse = float(np.sqrt(np.mean(np.square(core[\"err\"])))) if n_obs else np.nan\n",
        "    mae  = float(mean_absolute_error(core[\"y_true\"], core[\"y_pred\"])) if n_obs else np.nan\n",
        "\n",
        "    core[\"y_prev\"] = core[\"y_true\"].shift(1)\n",
        "    mask = core[\"y_prev\"].notna()\n",
        "    dir_true = np.sign(core.loc[mask, \"y_true\"] - core.loc[mask, \"y_prev\"])\n",
        "    dir_pred = np.sign(core.loc[mask, \"y_pred\"] - core.loc[mask, \"y_prev\"])\n",
        "    hits = int((dir_true.values == dir_pred.values).sum())\n",
        "    total = int(mask.sum())\n",
        "    hit_rate = (hits / total) if total else np.nan\n",
        "\n",
        "    print(\"\\n=== Model performance (monthly mean, EUR/NOK) ===\")\n",
        "    print(f\"Observations: {n_obs}\")\n",
        "    print(f\"RMSE (level): {rmse:.6f}\")\n",
        "    print(f\"MAE  (level): {mae:.6f}\")\n",
        "    if total:\n",
        "        print(f\"Directional accuracy: {hits}/{total} ({hit_rate*100:.1f}%)\")\n",
        "\n",
        "    return core\n",
        "\n",
        "# -----------------------------\n",
        "# Diebold–Mariano (vs Random Walk)\n",
        "# -----------------------------\n",
        "def _normal_cdf(z: float) -> float:\n",
        "    \"\"\"Standard normal CDF without scipy.\"\"\"\n",
        "    return 0.5 * (1.0 + math.erf(z / math.sqrt(2.0)))\n",
        "\n",
        "def dm_test(y_true: pd.Series, y_model: pd.Series, y_rw: pd.Series, h: int = 1, loss: str = \"mse\"):\n",
        "    \"\"\"\n",
        "    Diebold–Mariano test for equal predictive accuracy.\n",
        "    Returns (DM statistic, p-value). Uses simple NW/Bartlett HAC up to lag h-1.\n",
        "    \"\"\"\n",
        "    df = pd.concat({\"y\": y_true, \"m\": y_model, \"rw\": y_rw}, axis=1).dropna()\n",
        "    if df.empty or len(df) < 5:\n",
        "        return float(\"nan\"), float(\"nan\")\n",
        "\n",
        "    e_m = df[\"y\"] - df[\"m\"]\n",
        "    e_r = df[\"y\"] - df[\"rw\"]\n",
        "    d = np.abs(e_m) - np.abs(e_r) if loss.lower() == \"mae\" else (e_m**2) - (e_r**2)\n",
        "\n",
        "    N = int(len(d))\n",
        "    d_mean = float(d.mean())\n",
        "    gamma0 = float(np.var(d, ddof=1)) if N > 1 else 0.0\n",
        "    var_bar = gamma0 / N\n",
        "\n",
        "    if h > 1 and N > 2:\n",
        "        for k in range(1, min(h - 1, N - 1) + 1):\n",
        "            w_k = 1.0 - k / h\n",
        "            cov_k = float(np.cov(d[k:], d[:-k], ddof=1)[0, 1])\n",
        "            var_bar += 2.0 * w_k * cov_k / N\n",
        "\n",
        "    if var_bar <= 0 or not np.isfinite(var_bar):\n",
        "        return float(\"nan\"), float(\"nan\")\n",
        "\n",
        "    dm_stat = d_mean / math.sqrt(var_bar)\n",
        "    p_val = 2.0 * (1.0 - _normal_cdf(abs(dm_stat)))\n",
        "    return dm_stat, p_val\n",
        "\n",
        "def dm_against_random_walk(eval_df: pd.DataFrame, loss: str = \"mse\", h: int = 1):\n",
        "    \"\"\"Random walk benchmark = previous month's observed level (y_{t-1}).\"\"\"\n",
        "    df = eval_df.copy()\n",
        "    df[\"rw_pred\"] = df[\"y_true\"].shift(1)\n",
        "    dm_stat, p_val = dm_test(df[\"y_true\"], df[\"y_pred\"], df[\"rw_pred\"], h=h, loss=loss)\n",
        "    print(\"\\n=== Diebold–Mariano vs Random Walk ===\")\n",
        "    print(f\"Loss: {loss.upper()} | horizon h={h}\")\n",
        "    print(f\"DM-statistic: {dm_stat:.4f}\" if np.isfinite(dm_stat) else \"DM-statistic: nan\")\n",
        "    print(f\"p-value     : {p_val:.4f}\" if np.isfinite(p_val) else \"p-value     : nan\")\n",
        "\n",
        "# -----------------------------\n",
        "# Plot (no bands)\n",
        "# -----------------------------\n",
        "def plot_monthly_simple(eval_df: pd.DataFrame, png_path: str, pdf_path: str):\n",
        "    \"\"\"Simple line plot: actual vs forecast (monthly mean).\"\"\"\n",
        "    if eval_df.empty:\n",
        "        print(\"Nothing to plot.\")\n",
        "        return\n",
        "\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    x = eval_df.index.to_timestamp() if isinstance(eval_df.index, pd.PeriodIndex) else eval_df.index\n",
        "\n",
        "    plt.plot(x, eval_df[\"y_true\"], color=\"black\", label=\"Actual (monthly mean, B-days)\")\n",
        "    plt.plot(x, eval_df[\"y_pred\"], color=\"tab:blue\", linestyle=\"--\", label=\"Forecast (Gradient Boosting)\")\n",
        "\n",
        "    plt.title(\"Gradient Boosting Forecast vs Actual (Monthly Mean, EUR/NOK)\")\n",
        "    plt.xlabel(\"Month\")\n",
        "    plt.ylabel(\"Level\")\n",
        "    plt.legend()\n",
        "    plt.grid(True, alpha=0.3)\n",
        "    plt.tight_layout()\n",
        "\n",
        "    plt.savefig(png_path, dpi=300, bbox_inches=\"tight\")\n",
        "    plt.savefig(pdf_path, bbox_inches=\"tight\")\n",
        "    plt.show()\n",
        "    print(f\"Saved: {png_path}\")\n",
        "    print(f\"Saved: {pdf_path}\")\n",
        "\n",
        "# -----------------------------\n",
        "# Main\n",
        "# -----------------------------\n",
        "def main():\n",
        "    # 1) Data\n",
        "    S_b, S_d = load_series(CFG.url)\n",
        "    if CFG.verbose:\n",
        "        print(f\"Data (B): {S_b.index.min().date()} → {S_b.index.max().date()} | n={len(S_b)}\")\n",
        "        print(f\"Data (D): {S_d.index.min().date()} → {S_d.index.max().date()} | n={len(S_d)}\")\n",
        "\n",
        "    # 2) Monthly walk-forward and evaluation (parallel)\n",
        "    df_eval = walk_forward_gb_monthly_parallel(S_b, S_d, n_jobs_outer=-1)\n",
        "    eval_df = evaluate(df_eval)\n",
        "\n",
        "    # 3) Diebold–Mariano vs Random Walk (MSE; h=1)\n",
        "    dm_against_random_walk(eval_df, loss=\"mse\", h=1)\n",
        "\n",
        "    # 4) Plot\n",
        "    plot_monthly_simple(eval_df, CFG.fig_png, CFG.fig_pdf)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## GB_FX Price only Quarterly"
      ],
      "metadata": {
        "id": "QOaDnq3cRoEh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================================\n",
        "# Gradient Boosting – EUR/NOK walk-forward (quarterly, levels), point forecast only\n",
        "# - Data: GitHub CSV (semicolon-separated; decimal comma), forward-filled to daily\n",
        "# - Cut: last business day of previous quarter\n",
        "# - Model: GradientBoostingRegressor on daily lag features\n",
        "# - Forecast: recursive daily next-quarter -> aggregate to quarterly mean over business days\n",
        "# - Metrics: Observations, RMSE, MAE, Directional accuracy\n",
        "# - Test: Diebold–Mariano vs Random Walk (MSE, h=1)\n",
        "# - Plot: Actual (black) vs Forecast (blue dashed), no intervals\n",
        "# =========================================\n",
        "\n",
        "!pip -q install pandas numpy scikit-learn matplotlib requests certifi\n",
        "\n",
        "from __future__ import annotations\n",
        "import io, time, math\n",
        "from dataclasses import dataclass\n",
        "from typing import Optional, Tuple, Dict\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import requests, certifi\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "\n",
        "# -----------------------------\n",
        "# Configuration\n",
        "# -----------------------------\n",
        "@dataclass\n",
        "class Config:\n",
        "    url: str = (\n",
        "        \"https://raw.githubusercontent.com/bredeespelid/Data_MasterOppgave/\"\n",
        "        \"refs/heads/main/EURNOK/EUR_NOK_NorgesBank.csv\"\n",
        "    )\n",
        "    q_freq: str = \"Q-DEC\"      # quarterly evaluation\n",
        "    min_hist_days: int = 400   # GB needs more history\n",
        "    max_lags: int = 20         # number of daily lags used as features\n",
        "\n",
        "    # Gradient Boosting hyperparameters (tune if needed)\n",
        "    n_estimators: int = 800\n",
        "    learning_rate: float = 0.03\n",
        "    max_depth: int = 3         # tree depth per boosting stage\n",
        "    subsample: float = 0.8     # stochastic GB\n",
        "    min_samples_leaf: int = 2\n",
        "    random_state: int = 42\n",
        "\n",
        "    retries: int = 3\n",
        "    timeout: int = 60\n",
        "    verbose: bool = True\n",
        "    fig_png: str = \"GB_Quarterly.png\"\n",
        "    fig_pdf: str = \"GB_Quarterly.pdf\"\n",
        "\n",
        "CFG = Config()\n",
        "\n",
        "# -----------------------------\n",
        "# Download helper\n",
        "# -----------------------------\n",
        "def download_csv_text(url: str, retries: int, timeout: int) -> str:\n",
        "    \"\"\"Download CSV with simple retry/backoff.\"\"\"\n",
        "    last_err = None\n",
        "    for k in range(1, retries + 1):\n",
        "        try:\n",
        "            r = requests.get(url, timeout=timeout, verify=certifi.where())\n",
        "            r.raise_for_status()\n",
        "            return r.text\n",
        "        except Exception as e:\n",
        "            last_err = e\n",
        "            if k < retries:\n",
        "                wait = 1.5 * k\n",
        "                print(f\"[warning] Download failed (try {k}/{retries}): {e}. Retrying in {wait:.1f}s ...\")\n",
        "                time.sleep(wait)\n",
        "    raise RuntimeError(f\"Download failed: {last_err}\")\n",
        "\n",
        "# -----------------------------\n",
        "# Data loading\n",
        "# -----------------------------\n",
        "def load_series(url: str) -> Tuple[pd.Series, pd.Series]:\n",
        "    \"\"\"\n",
        "    Load Norges Bank CSV (semicolon-separated; decimal comma) with columns TIME_PERIOD, OBS_VALUE.\n",
        "    Returns:\n",
        "      S_b: business-day (B) with ffill (used for cuts and quarterly ground truth)\n",
        "      S_d: daily (D) with ffill (model inputs and daily forecasts)\n",
        "    \"\"\"\n",
        "    text = download_csv_text(url, CFG.retries, CFG.timeout)\n",
        "    raw = pd.read_csv(io.StringIO(text), sep=';', encoding='utf-8-sig', decimal=',')\n",
        "\n",
        "    required_cols = {\"TIME_PERIOD\", \"OBS_VALUE\"}\n",
        "    missing = required_cols - set(raw.columns)\n",
        "    if missing:\n",
        "        raise ValueError(f\"Missing columns in CSV: {missing}. Got: {list(raw.columns)}\")\n",
        "\n",
        "    df = (raw[['TIME_PERIOD', 'OBS_VALUE']]\n",
        "          .rename(columns={'OBS_VALUE': 'EUR_NOK'})\n",
        "          .assign(TIME_PERIOD=lambda x: pd.to_datetime(x['TIME_PERIOD'], errors='coerce'))\n",
        "          .dropna(subset=['TIME_PERIOD', 'EUR_NOK'])\n",
        "          .sort_values('TIME_PERIOD')\n",
        "          .set_index('TIME_PERIOD'))\n",
        "\n",
        "    # Business-day series (truth/aggregation base)\n",
        "    S_b = df['EUR_NOK'].asfreq('B').ffill().astype(float)\n",
        "    S_b.name = 'EUR_NOK'\n",
        "\n",
        "    # Daily series (model inputs / daily forecasts)\n",
        "    full_idx = pd.date_range(df.index.min(), df.index.max(), freq='D')\n",
        "    S_d = df['EUR_NOK'].reindex(full_idx).ffill().astype(float)\n",
        "    S_d.index.name = 'DATE'\n",
        "    S_d.name = 'EUR_NOK'\n",
        "    return S_b, S_d\n",
        "\n",
        "def last_trading_day(S_b: pd.Series, start: pd.Timestamp, end: pd.Timestamp) -> Optional[pd.Timestamp]:\n",
        "    \"\"\"Return the last business day in [start, end].\"\"\"\n",
        "    sl = S_b.loc[start:end]\n",
        "    return sl.index[-1] if not sl.empty else None\n",
        "\n",
        "# -----------------------------\n",
        "# Feature engineering (lags)\n",
        "# -----------------------------\n",
        "def make_lag_matrix(y: pd.Series, max_lags: int) -> Tuple[np.ndarray, np.ndarray]:\n",
        "    \"\"\"\n",
        "    Build X, y_target for one-step ahead forecasting:\n",
        "      X_t = [y_{t-1}, ..., y_{t-max_lags}]\n",
        "      y_target = y_t\n",
        "    \"\"\"\n",
        "    df = pd.DataFrame({'y': y})\n",
        "    for k in range(1, max_lags + 1):\n",
        "        df[f'lag{k}'] = df['y'].shift(k)\n",
        "    df = df.dropna()\n",
        "    X = df[[f'lag{k}' for k in range(1, max_lags + 1)]].values\n",
        "    y_target = df['y'].values\n",
        "    return X, y_target\n",
        "\n",
        "# -----------------------------\n",
        "# Gradient Boosting one-step model\n",
        "# -----------------------------\n",
        "def fit_gb_one_step(y_hist_daily: pd.Series) -> GradientBoostingRegressor:\n",
        "    \"\"\"Fit Gradient Boosting for one-step ahead daily prediction.\"\"\"\n",
        "    X, y_target = make_lag_matrix(y_hist_daily, CFG.max_lags)\n",
        "    model = GradientBoostingRegressor(\n",
        "        n_estimators=CFG.n_estimators,\n",
        "        learning_rate=CFG.learning_rate,\n",
        "        max_depth=CFG.max_depth,\n",
        "        subsample=CFG.subsample,\n",
        "        min_samples_leaf=CFG.min_samples_leaf,\n",
        "        random_state=CFG.random_state,\n",
        "    )\n",
        "    model.fit(X, y_target)\n",
        "    return model\n",
        "\n",
        "def recursive_daily_forecast(model: GradientBoostingRegressor, y_hist_daily: pd.Series, H: int) -> pd.Series:\n",
        "    \"\"\"\n",
        "    Produce H daily forecasts recursively:\n",
        "      - start from last max_lags observed values\n",
        "      - each step uses previous predicted value as newest lag\n",
        "    \"\"\"\n",
        "    hist = y_hist_daily.values.tolist()\n",
        "    preds = []\n",
        "    for _ in range(H):\n",
        "        if len(hist) < CFG.max_lags:\n",
        "            raise ValueError(\"Not enough history for lag features.\")\n",
        "        x = np.array(hist[-CFG.max_lags:][::-1], dtype=float).reshape(1, -1)\n",
        "        yhat = float(model.predict(x)[0])\n",
        "        preds.append(yhat)\n",
        "        hist.append(yhat)\n",
        "    return pd.Series(preds)\n",
        "\n",
        "# -----------------------------\n",
        "# Quarterly walk-forward using GB\n",
        "# -----------------------------\n",
        "def walk_forward_gb_quarterly(S_b: pd.Series, S_d: pd.Series) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    For each calendar quarter q:\n",
        "      - cut at last business day of previous quarter\n",
        "      - fit GB on daily history up to cut\n",
        "      - recursively forecast full calendar quarter at daily frequency\n",
        "      - aggregate to business-day quarterly mean and compare to truth\n",
        "    \"\"\"\n",
        "    first_q = pd.Period(S_b.index.min(), freq=CFG.q_freq)\n",
        "    last_q  = pd.Period(S_b.index.max(),  freq=CFG.q_freq)\n",
        "    quarters = pd.period_range(first_q, last_q, freq=CFG.q_freq)\n",
        "\n",
        "    rows: Dict = {}\n",
        "    dropped: Dict[str, str] = {}\n",
        "\n",
        "    for q in quarters:\n",
        "        prev_q = q - 1\n",
        "        q_start, q_end = q.start_time, q.end_time\n",
        "        prev_start, prev_end = prev_q.start_time, prev_q.end_time\n",
        "\n",
        "        cut = last_trading_day(S_b, prev_start, prev_end)\n",
        "        if cut is None:\n",
        "            dropped[str(q)] = \"no_cut_in_prev_quarter\"\n",
        "            continue\n",
        "\n",
        "        hist_d = S_d.loc[:cut]\n",
        "        if hist_d.size < CFG.min_hist_days:\n",
        "            dropped[str(q)] = f\"hist<{CFG.min_hist_days}\"\n",
        "            continue\n",
        "\n",
        "        # Business days inside target quarter\n",
        "        idx_q_b = S_b.index[(S_b.index >= q_start) & (S_b.index <= q_end)]\n",
        "        if idx_q_b.size < 1:\n",
        "            dropped[str(q)] = \"no_bdays_in_quarter\"\n",
        "            continue\n",
        "        y_true = float(S_b.loc[idx_q_b].mean())\n",
        "\n",
        "        # Horizon = full calendar quarter length (inclusive)\n",
        "        H = (q_end.date() - q_start.date()).days + 1\n",
        "        if H <= 0:\n",
        "            dropped[str(q)] = f\"horizon_invalid(H={H})\"\n",
        "            continue\n",
        "\n",
        "        # Fit model on daily history up to cut\n",
        "        model = fit_gb_one_step(hist_d)\n",
        "\n",
        "        # Recursive daily forecast for next quarter\n",
        "        pf = recursive_daily_forecast(model, hist_d, H)\n",
        "\n",
        "        # Index daily forecast from cut+1 over H calendar days\n",
        "        f_idx = pd.date_range(cut + pd.Timedelta(days=1), periods=H, freq='D')\n",
        "        pred_daily = pd.Series(pf.values, index=f_idx, name='point')\n",
        "\n",
        "        # Aggregate forecast to business-day mean over the quarter\n",
        "        pred_b = pred_daily.reindex(idx_q_b, method=None)\n",
        "        if pred_b.isna().all():\n",
        "            dropped[str(q)] = \"no_overlap_pred_B_days\"\n",
        "            continue\n",
        "        y_pred = float(pred_b.dropna().mean())\n",
        "\n",
        "        rows[str(q)] = {\"quarter\": q, \"cut\": cut, \"y_true\": y_true, \"y_pred\": y_pred}\n",
        "\n",
        "    df = pd.DataFrame.from_dict(rows, orient='index')\n",
        "    if not df.empty:\n",
        "        df = df.set_index(\"quarter\").sort_index()\n",
        "\n",
        "    if CFG.verbose and dropped:\n",
        "        miss = [str(q) for q in quarters if q not in df.index]\n",
        "        if miss:\n",
        "            print(\"\\nDropped quarters and reasons:\")\n",
        "            for qq in miss:\n",
        "                print(f\"  {qq}: {dropped.get(qq, 'unknown')}\")\n",
        "    return df\n",
        "\n",
        "# -----------------------------\n",
        "# Evaluation (level + direction)\n",
        "# -----------------------------\n",
        "def evaluate(eval_df: pd.DataFrame) -> pd.DataFrame:\n",
        "    \"\"\"Compute level errors and directional accuracy.\"\"\"\n",
        "    df = eval_df.copy()\n",
        "    df[\"err\"] = df[\"y_true\"] - df[\"y_pred\"]\n",
        "    core = df.dropna(subset=[\"y_true\", \"y_pred\"]).copy()\n",
        "\n",
        "    n_obs = int(len(core))\n",
        "    rmse = float(np.sqrt(np.mean(np.square(core[\"err\"])))) if n_obs else np.nan\n",
        "    mae  = float(mean_absolute_error(core[\"y_true\"], core[\"y_pred\"])) if n_obs else np.nan\n",
        "\n",
        "    core[\"y_prev\"] = core[\"y_true\"].shift(1)\n",
        "    mask = core[\"y_prev\"].notna()\n",
        "    dir_true = np.sign(core.loc[mask, \"y_true\"] - core.loc[mask, \"y_prev\"])\n",
        "    dir_pred = np.sign(core.loc[mask, \"y_pred\"] - core.loc[mask, \"y_prev\"])\n",
        "    hits = int((dir_true.values == dir_pred.values).sum())\n",
        "    total = int(mask.sum())\n",
        "    hit_rate = (hits / total) if total else np.nan\n",
        "\n",
        "    print(\"\\n=== Model performance (quarterly mean, EUR/NOK) ===\")\n",
        "    print(f\"Observations: {n_obs}\")\n",
        "    print(f\"RMSE (level): {rmse:.6f}\")\n",
        "    print(f\"MAE  (level): {mae:.6f}\")\n",
        "    if total:\n",
        "        print(f\"Directional accuracy: {hits}/{total} ({hit_rate*100:.1f}%)\")\n",
        "\n",
        "    return core\n",
        "\n",
        "# -----------------------------\n",
        "# Diebold–Mariano (vs Random Walk)\n",
        "# -----------------------------\n",
        "def _normal_cdf(z: float) -> float:\n",
        "    \"\"\"Standard normal CDF without scipy.\"\"\"\n",
        "    return 0.5 * (1.0 + math.erf(z / math.sqrt(2.0)))\n",
        "\n",
        "def dm_test(y_true: pd.Series, y_model: pd.Series, y_rw: pd.Series, h: int = 1, loss: str = \"mse\") -> Tuple[float, float]:\n",
        "    \"\"\"\n",
        "    Diebold–Mariano test for equal predictive accuracy.\n",
        "    Returns (DM statistic, p-value). Uses simple NW/Bartlett HAC up to lag h-1.\n",
        "    \"\"\"\n",
        "    df = pd.concat({\"y\": y_true, \"m\": y_model, \"rw\": y_rw}, axis=1).dropna()\n",
        "    if df.empty or len(df) < 5:\n",
        "        return float(\"nan\"), float(\"nan\")\n",
        "\n",
        "    e_m = df[\"y\"] - df[\"m\"]\n",
        "    e_r = df[\"y\"] - df[\"rw\"]\n",
        "    d = np.abs(e_m) - np.abs(e_r) if loss.lower() == \"mae\" else (e_m**2) - (e_r**2)\n",
        "\n",
        "    N = int(len(d))\n",
        "    d_mean = float(d.mean())\n",
        "    gamma0 = float(np.var(d, ddof=1)) if N > 1 else 0.0\n",
        "    var_bar = gamma0 / N\n",
        "\n",
        "    if h > 1 and N > 2:\n",
        "        for k in range(1, min(h - 1, N - 1) + 1):\n",
        "            w_k = 1.0 - k / h\n",
        "            cov_k = float(np.cov(d[k:], d[:-k], ddof=1)[0, 1])\n",
        "            var_bar += 2.0 * w_k * cov_k / N\n",
        "\n",
        "    if var_bar <= 0 or not np.isfinite(var_bar):\n",
        "        return float(\"nan\"), float(\"nan\")\n",
        "\n",
        "    dm_stat = d_mean / math.sqrt(var_bar)\n",
        "    p_val = 2.0 * (1.0 - _normal_cdf(abs(dm_stat)))\n",
        "    return dm_stat, p_val\n",
        "\n",
        "def dm_against_random_walk(eval_df: pd.DataFrame, loss: str = \"mse\", h: int = 1) -> None:\n",
        "    \"\"\"Random walk benchmark = previous quarter's observed level (y_{t-1}).\"\"\"\n",
        "    df = eval_df.copy()\n",
        "    df[\"rw_pred\"] = df[\"y_true\"].shift(1)\n",
        "    dm_stat, p_val = dm_test(df[\"y_true\"], df[\"y_pred\"], df[\"rw_pred\"], h=h, loss=loss)\n",
        "    print(\"\\n=== Diebold–Mariano vs Random Walk ===\")\n",
        "    print(f\"Loss: {loss.upper()} | horizon h={h}\")\n",
        "    print(f\"DM-statistic: {dm_stat:.4f}\" if np.isfinite(dm_stat) else \"DM-statistic: nan\")\n",
        "    print(f\"p-value     : {p_val:.4f}\" if np.isfinite(p_val) else \"p-value     : nan\")\n",
        "\n",
        "# -----------------------------\n",
        "# Plot (no bands)\n",
        "# -----------------------------\n",
        "def plot_quarterly_simple(eval_df: pd.DataFrame, png_path: str, pdf_path: str):\n",
        "    \"\"\"Simple line plot: actual vs forecast (quarterly mean).\"\"\"\n",
        "    if eval_df.empty:\n",
        "        print(\"Nothing to plot.\")\n",
        "        return\n",
        "\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    x = eval_df.index.to_timestamp() if isinstance(eval_df.index, pd.PeriodIndex) else eval_df.index\n",
        "\n",
        "    plt.plot(x, eval_df[\"y_true\"], color=\"black\", label=\"Actual (quarterly mean, B-days)\")\n",
        "    plt.plot(x, eval_df[\"y_pred\"], color=\"tab:blue\", linestyle=\"--\", label=\"Forecast (Gradient Boosting)\")\n",
        "\n",
        "    plt.title(\"Gradient Boosting Forecast vs Actual (Quarterly Mean, EUR/NOK)\")\n",
        "    plt.xlabel(\"Quarter\")\n",
        "    plt.ylabel(\"Level\")\n",
        "    plt.legend()\n",
        "    plt.grid(True, alpha=0.3)\n",
        "    plt.tight_layout()\n",
        "\n",
        "    plt.savefig(png_path, dpi=300, bbox_inches=\"tight\")\n",
        "    plt.savefig(pdf_path, bbox_inches=\"tight\")\n",
        "    plt.show()\n",
        "    print(f\"Saved: {png_path}\")\n",
        "    print(f\"Saved: {pdf_path}\")\n",
        "\n",
        "# -----------------------------\n",
        "# Main\n",
        "# -----------------------------\n",
        "def main():\n",
        "    # 1) Data\n",
        "    S_b, S_d = load_series(CFG.url)\n",
        "    if CFG.verbose:\n",
        "        print(f\"Data (B): {S_b.index.min().date()} → {S_b.index.max().date()} | n={len(S_b)}\")\n",
        "        print(f\"Data (D): {S_d.index.min().date()} → {S_d.index.max().date()} | n={len(S_d)}\")\n",
        "\n",
        "    # 2) Quarterly walk-forward and evaluation\n",
        "    df_eval = walk_forward_gb_quarterly(S_b, S_d)\n",
        "    eval_df = evaluate(df_eval)\n",
        "\n",
        "    # 3) Diebold–Mariano vs Random Walk (MSE; h=1)\n",
        "    dm_against_random_walk(eval_df, loss=\"mse\", h=1)\n",
        "\n",
        "    # 4) Plot\n",
        "    plot_quarterly_simple(eval_df, CFG.fig_png, CFG.fig_pdf)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "id": "lZT2d70VSjzl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## GB_FX Macro Monthly"
      ],
      "metadata": {
        "id": "A8bRN-HFSp2g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================================\n",
        "# Gradient Boosting – EUR/NOK walk-forward (monthly, levels) with daily macro covariates\n",
        "# Univariate setup:\n",
        "#   - Target: EUR_NOK (single series)\n",
        "#   - Macros: Q, d_pi, dI_t as past-only covariates\n",
        "#   - Data: daily (calendar days), forward-filled\n",
        "#   - Cut: last business day of previous month (based on EUR_NOK B-days)\n",
        "#   - Forecast: next calendar month at daily frequency (recursive one-step GB),\n",
        "#               aggregated to monthly mean over business days (EUR/NOK)\n",
        "#   - No future macro paths used -> macros are frozen at last observed value during recursion\n",
        "#   - Metrics: Observations, RMSE, MAE, Directional accuracy\n",
        "#   - Test: Diebold–Mariano vs Random Walk (MSE, h=1)\n",
        "#   - Plot: Actual (black) vs Forecast (blue dashed), no intervals\n",
        "# =========================================\n",
        "\n",
        "!pip -q install pandas numpy scikit-learn matplotlib requests certifi\n",
        "\n",
        "from __future__ import annotations\n",
        "import io, time, math\n",
        "from dataclasses import dataclass\n",
        "from typing import Optional, Tuple, Dict, List\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import requests, certifi\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "\n",
        "# -----------------------------\n",
        "# Configuration\n",
        "# -----------------------------\n",
        "@dataclass\n",
        "class Config:\n",
        "    url: str = (\n",
        "        \"https://raw.githubusercontent.com/bredeespelid/\"\n",
        "        \"Data_MasterOppgave/refs/heads/main/Variables/All_Variables/variables_daily.csv\"\n",
        "    )\n",
        "    m_freq: str = \"M\"\n",
        "    min_hist_days: int = 400   # GB + macro needs more history to stabilize\n",
        "    max_lags: int = 20         # number of daily lags per variable\n",
        "\n",
        "    # Gradient Boosting hyperparameters\n",
        "    n_estimators: int = 800\n",
        "    learning_rate: float = 0.03\n",
        "    max_depth: int = 3\n",
        "    subsample: float = 0.8\n",
        "    min_samples_leaf: int = 2\n",
        "    random_state: int = 42\n",
        "\n",
        "    retries: int = 3\n",
        "    timeout: int = 60\n",
        "    verbose: bool = True\n",
        "    fig_png: str = \"GB_M_daily_pastcov.png\"\n",
        "    fig_pdf: str = \"GB_M_daily_pastcov.pdf\"\n",
        "\n",
        "CFG = Config()\n",
        "\n",
        "TARGET_SERIES = \"EUR_NOK\"\n",
        "MACRO_COLS = [\"Q\", \"d_pi\", \"dI_t\"]\n",
        "\n",
        "# -----------------------------\n",
        "# Download helper\n",
        "# -----------------------------\n",
        "def download_csv_text(url: str, retries: int, timeout: int) -> str:\n",
        "    \"\"\"Download CSV with simple retry/backoff.\"\"\"\n",
        "    last_err = None\n",
        "    for k in range(1, retries + 1):\n",
        "        try:\n",
        "            r = requests.get(url, timeout=timeout, verify=certifi.where())\n",
        "            r.raise_for_status()\n",
        "            return r.text\n",
        "        except Exception as e:\n",
        "            last_err = e\n",
        "            if k < retries:\n",
        "                wait = 1.5 * k\n",
        "                print(f\"[warning] Download failed (try {k}/{retries}): {e}. Retrying in {wait:.1f}s ...\")\n",
        "                time.sleep(wait)\n",
        "    raise RuntimeError(f\"Download failed: {last_err}\")\n",
        "\n",
        "# -----------------------------\n",
        "# Data loading: daily EUR_NOK (B + D) + macro covariates\n",
        "# -----------------------------\n",
        "def load_series(url: str) -> Tuple[pd.Series, pd.DataFrame]:\n",
        "    \"\"\"\n",
        "    Load daily CSV with columns:\n",
        "      Date, EUR_NOK, Q, d_pi, dI_t\n",
        "\n",
        "    Returns:\n",
        "      S_b  : EUR_NOK on business days (B) with ffill (for cuts and monthly ground truth)\n",
        "      DF_d : daily (D) DataFrame with columns [EUR_NOK, Q, d_pi, dI_t],\n",
        "             calendar days, forward-filled\n",
        "    \"\"\"\n",
        "    text = download_csv_text(url, CFG.retries, CFG.timeout)\n",
        "    raw = pd.read_csv(io.StringIO(text))\n",
        "\n",
        "    required_cols = {\"Date\", \"EUR_NOK\", \"Q\", \"d_pi\", \"dI_t\"}\n",
        "    missing = required_cols - set(raw.columns)\n",
        "    if missing:\n",
        "        raise ValueError(f\"Missing columns in CSV: {missing}. Got: {list(raw.columns)}\")\n",
        "\n",
        "    df = (\n",
        "        raw[list(required_cols)]\n",
        "        .rename(columns={\"Date\": \"DATE\"})\n",
        "        .assign(DATE=lambda x: pd.to_datetime(x[\"DATE\"], errors=\"coerce\"))\n",
        "        .dropna(subset=[\"DATE\", \"EUR_NOK\"])\n",
        "        .sort_values(\"DATE\")\n",
        "        .set_index(\"DATE\")\n",
        "    )\n",
        "\n",
        "    # Ensure numeric types\n",
        "    for col in [TARGET_SERIES] + MACRO_COLS:\n",
        "        df[col] = pd.to_numeric(df[col], errors=\"coerce\")\n",
        "    df = df.dropna(subset=[TARGET_SERIES])\n",
        "\n",
        "    # Business-day EUR_NOK (truth/aggregation base)\n",
        "    S_b = df[TARGET_SERIES].asfreq(\"B\").ffill().astype(float)\n",
        "    S_b.name = TARGET_SERIES\n",
        "\n",
        "    # Daily DF_d (calendar days, forward-filled)\n",
        "    full_idx = pd.date_range(df.index.min(), df.index.max(), freq=\"D\")\n",
        "    DF_d = df.reindex(full_idx).ffill()\n",
        "    DF_d.index.name = \"DATE\"\n",
        "\n",
        "    return S_b, DF_d\n",
        "\n",
        "def last_trading_day(S_b: pd.Series, start: pd.Timestamp, end: pd.Timestamp) -> Optional[pd.Timestamp]:\n",
        "    \"\"\"Return the last business day in [start, end].\"\"\"\n",
        "    sl = S_b.loc[start:end]\n",
        "    return sl.index[-1] if not sl.empty else None\n",
        "\n",
        "# -----------------------------\n",
        "# Feature engineering (multivariate lags)\n",
        "# -----------------------------\n",
        "def make_lag_matrix(df_hist: pd.DataFrame, max_lags: int) -> Tuple[np.ndarray, np.ndarray]:\n",
        "    \"\"\"\n",
        "    Build X, y_target for one-step ahead daily forecasting.\n",
        "\n",
        "    For each t:\n",
        "      X_t = [EUR_NOK_{t-1..t-L}, Q_{t-1..t-L}, d_pi_{t-1..t-L}, dI_t_{t-1..t-L}]\n",
        "      y_target = EUR_NOK_t\n",
        "    \"\"\"\n",
        "    work = df_hist[[TARGET_SERIES] + MACRO_COLS].copy()\n",
        "    lag_cols: List[str] = []\n",
        "\n",
        "    for var in [TARGET_SERIES] + MACRO_COLS:\n",
        "        for k in range(1, max_lags + 1):\n",
        "            name = f\"{var}_lag{k}\"\n",
        "            work[name] = work[var].shift(k)\n",
        "            lag_cols.append(name)\n",
        "\n",
        "    work = work.dropna()\n",
        "    X = work[lag_cols].values\n",
        "    y_target = work[TARGET_SERIES].values\n",
        "    return X, y_target\n",
        "\n",
        "# -----------------------------\n",
        "# Gradient Boosting one-step model\n",
        "# -----------------------------\n",
        "def fit_gb_one_step(df_hist_daily: pd.DataFrame) -> GradientBoostingRegressor:\n",
        "    \"\"\"Fit Gradient Boosting for one-step ahead daily prediction using lagged target + lagged macros.\"\"\"\n",
        "    X, y_target = make_lag_matrix(df_hist_daily, CFG.max_lags)\n",
        "    model = GradientBoostingRegressor(\n",
        "        n_estimators=CFG.n_estimators,\n",
        "        learning_rate=CFG.learning_rate,\n",
        "        max_depth=CFG.max_depth,\n",
        "        subsample=CFG.subsample,\n",
        "        min_samples_leaf=CFG.min_samples_leaf,\n",
        "        random_state=CFG.random_state,\n",
        "    )\n",
        "    model.fit(X, y_target)\n",
        "    return model\n",
        "\n",
        "def recursive_daily_forecast(model: GradientBoostingRegressor, df_hist_daily: pd.DataFrame, H: int) -> pd.Series:\n",
        "    \"\"\"\n",
        "    Produce H daily forecasts recursively.\n",
        "\n",
        "    Important anti-leakage rule:\n",
        "      - Macros are treated as past-only covariates.\n",
        "      - During recursion we freeze macro values at their last observed level.\n",
        "    \"\"\"\n",
        "    hist = df_hist_daily[[TARGET_SERIES] + MACRO_COLS].copy()\n",
        "\n",
        "    # Last observed macro level (frozen into the future)\n",
        "    last_macros = hist[MACRO_COLS].iloc[-1].to_dict()\n",
        "\n",
        "    preds = []\n",
        "    for _ in range(H):\n",
        "        if len(hist) < CFG.max_lags:\n",
        "            raise ValueError(\"Not enough history for lag features.\")\n",
        "\n",
        "        # Build one-step feature vector from last L lags\n",
        "        row_feats = []\n",
        "        for var in [TARGET_SERIES] + MACRO_COLS:\n",
        "            lags = hist[var].iloc[-CFG.max_lags:][::-1].values  # [t-1, ..., t-L]\n",
        "            row_feats.extend(lags.tolist())\n",
        "\n",
        "        x = np.array(row_feats, dtype=float).reshape(1, -1)\n",
        "        yhat = float(model.predict(x)[0])\n",
        "        preds.append(yhat)\n",
        "\n",
        "        # Append predicted target; append frozen macros\n",
        "        new_row = {TARGET_SERIES: yhat}\n",
        "        for mc in MACRO_COLS:\n",
        "            new_row[mc] = last_macros[mc]\n",
        "\n",
        "        hist = pd.concat([hist, pd.DataFrame([new_row], index=[hist.index[-1] + pd.Timedelta(days=1)])])\n",
        "\n",
        "    return pd.Series(preds)\n",
        "\n",
        "# -----------------------------\n",
        "# Monthly walk-forward using GB + past macros\n",
        "# -----------------------------\n",
        "def walk_forward_gb_monthly_pastcov(S_b: pd.Series, DF_d: pd.DataFrame) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    For each calendar month m:\n",
        "      - cut at last business day of previous month\n",
        "      - fit GB on daily history up to cut (EUR_NOK + macros)\n",
        "      - recursively forecast full next month at daily frequency\n",
        "      - aggregate to business-day monthly mean and compare to truth\n",
        "    \"\"\"\n",
        "    first_m = pd.Period(S_b.index.min(), freq=CFG.m_freq)\n",
        "    last_m  = pd.Period(S_b.index.max(), freq=CFG.m_freq)\n",
        "    months = pd.period_range(first_m, last_m, freq=CFG.m_freq)\n",
        "\n",
        "    rows: Dict = {}\n",
        "    dropped: Dict[str, str] = {}\n",
        "\n",
        "    for m in months:\n",
        "        prev_m = m - 1\n",
        "        m_start, m_end = m.start_time, m.end_time\n",
        "        prev_start, prev_end = prev_m.start_time, prev_m.end_time\n",
        "\n",
        "        cut = last_trading_day(S_b, prev_start, prev_end)\n",
        "        if cut is None:\n",
        "            dropped[str(m)] = \"no_cut_in_prev_month\"\n",
        "            continue\n",
        "\n",
        "        hist_df = DF_d.loc[:cut]\n",
        "        if hist_df.shape[0] < CFG.min_hist_days:\n",
        "            dropped[str(m)] = f\"hist<{CFG.min_hist_days}\"\n",
        "            continue\n",
        "\n",
        "        # Business days inside target month\n",
        "        idx_m_b = S_b.index[(S_b.index >= m_start) & (S_b.index <= m_end)]\n",
        "        if idx_m_b.size < 1:\n",
        "            dropped[str(m)] = \"no_bdays_in_month\"\n",
        "            continue\n",
        "        y_true = float(S_b.loc[idx_m_b].mean())\n",
        "\n",
        "        # Horizon = full calendar month length (inclusive)\n",
        "        H = (m_end.date() - m_start.date()).days + 1\n",
        "        if H <= 0:\n",
        "            dropped[str(m)] = f\"horizon_invalid(H={H})\"\n",
        "            continue\n",
        "\n",
        "        # Fit GB and forecast recursively\n",
        "        model = fit_gb_one_step(hist_df)\n",
        "        pf = recursive_daily_forecast(model, hist_df, H)\n",
        "\n",
        "        f_idx = pd.date_range(cut + pd.Timedelta(days=1), periods=H, freq=\"D\")\n",
        "        pred_daily = pd.Series(pf.values, index=f_idx, name=\"point\")\n",
        "\n",
        "        # Aggregate forecast to business-day mean\n",
        "        pred_b = pred_daily.reindex(idx_m_b, method=None)\n",
        "        if pred_b.isna().all():\n",
        "            dropped[str(m)] = \"no_overlap_pred_B_days\"\n",
        "            continue\n",
        "        y_pred = float(pred_b.dropna().mean())\n",
        "\n",
        "        rows[str(m)] = {\"month\": m, \"cut\": cut, \"y_true\": y_true, \"y_pred\": y_pred}\n",
        "\n",
        "    df = pd.DataFrame.from_dict(rows, orient=\"index\")\n",
        "    if not df.empty:\n",
        "        df = df.set_index(\"month\").sort_index()\n",
        "\n",
        "    if CFG.verbose and dropped:\n",
        "        miss = [str(m) for m in months if m not in df.index]\n",
        "        if miss:\n",
        "            print(\"\\nDropped months and reasons:\")\n",
        "            for mm in miss:\n",
        "                print(f\"  {mm}: {dropped.get(mm, 'unknown')}\")\n",
        "    return df\n",
        "\n",
        "# -----------------------------\n",
        "# Evaluation (level + direction)\n",
        "# -----------------------------\n",
        "def evaluate(eval_df: pd.DataFrame) -> pd.DataFrame:\n",
        "    \"\"\"Compute level errors and directional accuracy.\"\"\"\n",
        "    df = eval_df.copy()\n",
        "    df[\"err\"] = df[\"y_true\"] - df[\"y_pred\"]\n",
        "    core = df.dropna(subset=[\"y_true\", \"y_pred\"]).copy()\n",
        "\n",
        "    n_obs = int(len(core))\n",
        "    rmse = float(np.sqrt(np.mean(np.square(core[\"err\"])))) if n_obs else np.nan\n",
        "    mae  = float(mean_absolute_error(core[\"y_true\"], core[\"y_pred\"])) if n_obs else np.nan\n",
        "\n",
        "    core[\"y_prev\"] = core[\"y_true\"].shift(1)\n",
        "    mask = core[\"y_prev\"].notna()\n",
        "    dir_true = np.sign(core.loc[mask, \"y_true\"] - core.loc[mask, \"y_prev\"])\n",
        "    dir_pred = np.sign(core.loc[mask, \"y_pred\"] - core.loc[mask, \"y_prev\"])\n",
        "    hits = int((dir_true.values == dir_pred.values).sum())\n",
        "    total = int(mask.sum())\n",
        "    hit_rate = (hits / total) if total else np.nan\n",
        "\n",
        "    print(\"\\n=== Model performance (monthly mean, EUR/NOK – GB past macro covariates) ===\")\n",
        "    print(f\"Observations: {n_obs}\")\n",
        "    print(f\"RMSE (level): {rmse:.6f}\")\n",
        "    print(f\"MAE  (level): {mae:.6f}\")\n",
        "    if total:\n",
        "        print(f\"Directional accuracy: {hits}/{total} ({hit_rate*100:.1f}%)\")\n",
        "\n",
        "    return core\n",
        "\n",
        "# -----------------------------\n",
        "# Diebold–Mariano (vs Random Walk)\n",
        "# -----------------------------\n",
        "def _normal_cdf(z: float) -> float:\n",
        "    \"\"\"Standard normal CDF without scipy.\"\"\"\n",
        "    return 0.5 * (1.0 + math.erf(z / math.sqrt(2.0)))\n",
        "\n",
        "def dm_test(y_true: pd.Series, y_model: pd.Series, y_rw: pd.Series, h: int = 1, loss: str = \"mse\") -> Tuple[float, float]:\n",
        "    \"\"\"\n",
        "    Diebold–Mariano test for equal predictive accuracy.\n",
        "    Returns (DM statistic, p-value). Uses simple Newey–West/Bartlett HAC up to lag h-1.\n",
        "    \"\"\"\n",
        "    df = pd.concat({\"y\": y_true, \"m\": y_model, \"rw\": y_rw}, axis=1).dropna()\n",
        "    if df.empty or len(df) < 5:\n",
        "        return float(\"nan\"), float(\"nan\")\n",
        "\n",
        "    e_m = df[\"y\"] - df[\"m\"]\n",
        "    e_r = df[\"y\"] - df[\"rw\"]\n",
        "    d = np.abs(e_m) - np.abs(e_r) if loss.lower() == \"mae\" else (e_m**2) - (e_r**2)\n",
        "\n",
        "    N = int(len(d))\n",
        "    d_mean = float(d.mean())\n",
        "    gamma0 = float(np.var(d, ddof=1)) if N > 1 else 0.0\n",
        "    var_bar = gamma0 / N\n",
        "\n",
        "    if h > 1 and N > 2:\n",
        "        for k in range(1, min(h - 1, N - 1) + 1):\n",
        "            w_k = 1.0 - k / h\n",
        "            cov_k = float(np.cov(d[k:], d[:-k], ddof=1)[0, 1])\n",
        "            var_bar += 2.0 * w_k * cov_k / N\n",
        "\n",
        "    if var_bar <= 0 or not np.isfinite(var_bar):\n",
        "        return float(\"nan\"), float(\"nan\")\n",
        "\n",
        "    dm_stat = d_mean / math.sqrt(var_bar)\n",
        "    p_val = 2.0 * (1.0 - _normal_cdf(abs(dm_stat)))\n",
        "    return dm_stat, p_val\n",
        "\n",
        "def dm_against_random_walk(eval_df: pd.DataFrame, loss: str = \"mse\", h: int = 1) -> None:\n",
        "    \"\"\"Random walk benchmark = previous month's observed level (y_{t-1}).\"\"\"\n",
        "    df = eval_df.copy()\n",
        "    df[\"rw_pred\"] = df[\"y_true\"].shift(1)\n",
        "    dm_stat, p_val = dm_test(df[\"y_true\"], df[\"y_pred\"], df[\"rw_pred\"], h=h, loss=loss)\n",
        "    print(\"\\n=== Diebold–Mariano vs Random Walk (GB past macro covariates, monthly) ===\")\n",
        "    print(f\"Loss: {loss.upper()} | horizon h={h}\")\n",
        "    print(f\"DM-statistic: {dm_stat:.4f}\" if np.isfinite(dm_stat) else \"DM-statistic: nan\")\n",
        "    print(f\"p-value     : {p_val:.4f}\" if np.isfinite(p_val) else \"p-value     : nan\")\n",
        "\n",
        "# -----------------------------\n",
        "# Plot (no bands)\n",
        "# -----------------------------\n",
        "def plot_monthly_simple(eval_df: pd.DataFrame, png_path: str, pdf_path: str):\n",
        "    \"\"\"Simple line plot: actual vs forecast (monthly mean).\"\"\"\n",
        "    if eval_df.empty:\n",
        "        print(\"Nothing to plot.\")\n",
        "        return\n",
        "\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    x = eval_df.index.to_timestamp() if isinstance(eval_df.index, pd.PeriodIndex) else eval_df.index\n",
        "\n",
        "    plt.plot(x, eval_df[\"y_true\"], color=\"black\", label=\"Actual (monthly mean, B-days)\")\n",
        "    plt.plot(x, eval_df[\"y_pred\"], color=\"tab:blue\", linestyle=\"--\",\n",
        "             label=\"Forecast (Gradient Boosting, past macro covariates)\")\n",
        "\n",
        "    plt.title(\"Gradient Boosting Forecast vs Actual (Monthly Mean, EUR/NOK – past macro covariates)\")\n",
        "    plt.xlabel(\"Month\")\n",
        "    plt.ylabel(\"Level\")\n",
        "    plt.legend()\n",
        "    plt.grid(True, alpha=0.3)\n",
        "    plt.tight_layout()\n",
        "\n",
        "    plt.savefig(png_path, dpi=300, bbox_inches=\"tight\")\n",
        "    plt.savefig(pdf_path, bbox_inches=\"tight\")\n",
        "    plt.show()\n",
        "    print(f\"Saved: {png_path}\")\n",
        "    print(f\"Saved: {pdf_path}\")\n",
        "\n",
        "# -----------------------------\n",
        "# Main\n",
        "# -----------------------------\n",
        "def main():\n",
        "    # 1) Data\n",
        "    S_b, DF_d = load_series(CFG.url)\n",
        "    if CFG.verbose:\n",
        "        print(f\"Data (B): {S_b.index.min().date()} → {S_b.index.max().date()} | n={len(S_b)}\")\n",
        "        print(f\"Data (D): {DF_d.index.min().date()} → {DF_d.index.max().date()} | n={len(DF_d)}\")\n",
        "        print(f\"Columns (DF_d): {list(DF_d.columns)}\")\n",
        "\n",
        "    # 2) Monthly walk-forward and evaluation\n",
        "    df_eval = walk_forward_gb_monthly_pastcov(S_b, DF_d)\n",
        "    eval_df = evaluate(df_eval)\n",
        "\n",
        "    # 3) Diebold–Mariano vs Random Walk (MSE; h=1)\n",
        "    dm_against_random_walk(eval_df, loss=\"mse\", h=1)\n",
        "\n",
        "    # 4) Plot\n",
        "    plot_monthly_simple(eval_df, CFG.fig_png, CFG.fig_pdf)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "id": "X9F1aZC_S4Ah"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## GB_Fx-Quarterly_Macro\n"
      ],
      "metadata": {
        "id": "cizQSSkHS7fn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================================\n",
        "# Gradient Boosting – EUR/NOK walk-forward (quarterly, levels) with daily macro covariates\n",
        "# Univariate setup:\n",
        "#   - Target: EUR_NOK (single series)\n",
        "#   - Macros: Q, d_pi, dI_t as past-only covariates\n",
        "#   - Data: daily (calendar days), forward-filled\n",
        "#   - Cut: last business day of previous quarter (based on EUR_NOK B-days)\n",
        "#   - Forecast: next calendar quarter at daily frequency (recursive one-step GB),\n",
        "#               aggregated to quarterly mean over business days (EUR/NOK)\n",
        "#   - No future macro paths used -> macros are frozen at last observed value during recursion\n",
        "#   - Metrics: Observations, RMSE, MAE, Directional accuracy\n",
        "#   - Test: Diebold–Mariano vs Random Walk (MSE, h=1)\n",
        "#   - Plot: Actual (black) vs Forecast (blue dashed), no intervals\n",
        "# =========================================\n",
        "\n",
        "!pip -q install pandas numpy scikit-learn matplotlib requests certifi\n",
        "\n",
        "from __future__ import annotations\n",
        "import io, time, math\n",
        "from dataclasses import dataclass\n",
        "from typing import Optional, Tuple, Dict, List\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import requests, certifi\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "\n",
        "# -----------------------------\n",
        "# Configuration\n",
        "# -----------------------------\n",
        "@dataclass\n",
        "class Config:\n",
        "    url: str = (\n",
        "        \"https://raw.githubusercontent.com/bredeespelid/\"\n",
        "        \"Data_MasterOppgave/refs/heads/main/Variables/All_Variables/variables_daily.csv\"\n",
        "    )\n",
        "    q_freq: str = \"Q-DEC\"      # quarterly evaluation\n",
        "    min_hist_days: int = 400   # GB + macro needs more history to stabilize\n",
        "    max_lags: int = 20         # number of daily lags per variable\n",
        "    max_horizon: int = 128     # must exceed longest quarter (~92 days)\n",
        "\n",
        "    # Gradient Boosting hyperparameters\n",
        "    n_estimators: int = 1200\n",
        "    learning_rate: float = 0.03\n",
        "    max_depth: int = 3\n",
        "    subsample: float = 0.8\n",
        "    min_samples_leaf: int = 2\n",
        "    random_state: int = 42\n",
        "\n",
        "    retries: int = 3\n",
        "    timeout: int = 60\n",
        "    verbose: bool = True\n",
        "    fig_png: str = \"GB_Q_daily_pastcov.png\"\n",
        "    fig_pdf: str = \"GB_Q_daily_pastcov.pdf\"\n",
        "\n",
        "CFG = Config()\n",
        "\n",
        "TARGET_SERIES = \"EUR_NOK\"\n",
        "MACRO_COLS = [\"Q\", \"d_pi\", \"dI_t\"]\n",
        "\n",
        "# -----------------------------\n",
        "# Download helper\n",
        "# -----------------------------\n",
        "def download_csv_text(url: str, retries: int, timeout: int) -> str:\n",
        "    \"\"\"Download CSV with simple retry/backoff.\"\"\"\n",
        "    last_err = None\n",
        "    for k in range(1, retries + 1):\n",
        "        try:\n",
        "            r = requests.get(url, timeout=timeout, verify=certifi.where())\n",
        "            r.raise_for_status()\n",
        "            return r.text\n",
        "        except Exception as e:\n",
        "            last_err = e\n",
        "            if k < retries:\n",
        "                wait = 1.5 * k\n",
        "                print(f\"[warning] Download failed (try {k}/{retries}): {e}. Retrying in {wait:.1f}s ...\")\n",
        "                time.sleep(wait)\n",
        "    raise RuntimeError(f\"Download failed: {last_err}\")\n",
        "\n",
        "# -----------------------------\n",
        "# Data loading: daily EUR_NOK (B + D) + macro covariates\n",
        "# -----------------------------\n",
        "def load_series(url: str) -> Tuple[pd.Series, pd.DataFrame]:\n",
        "    \"\"\"\n",
        "    Load daily CSV with columns:\n",
        "      Date, EUR_NOK, Q, d_pi, dI_t\n",
        "\n",
        "    Returns:\n",
        "      S_b  : EUR_NOK on business days (B) with ffill (for cuts and quarterly ground truth)\n",
        "      DF_d : daily (D) DataFrame with columns [EUR_NOK, Q, d_pi, dI_t],\n",
        "             calendar days, forward-filled\n",
        "    \"\"\"\n",
        "    text = download_csv_text(url, CFG.retries, CFG.timeout)\n",
        "    raw = pd.read_csv(io.StringIO(text))\n",
        "\n",
        "    required_cols = {\"Date\", \"EUR_NOK\", \"Q\", \"d_pi\", \"dI_t\"}\n",
        "    missing = required_cols - set(raw.columns)\n",
        "    if missing:\n",
        "        raise ValueError(f\"Missing columns in CSV: {missing}. Got: {list(raw.columns)}\")\n",
        "\n",
        "    df = (\n",
        "        raw[list(required_cols)]\n",
        "        .rename(columns={\"Date\": \"DATE\"})\n",
        "        .assign(DATE=lambda x: pd.to_datetime(x[\"DATE\"], errors=\"coerce\"))\n",
        "        .dropna(subset=[\"DATE\", \"EUR_NOK\"])\n",
        "        .sort_values(\"DATE\")\n",
        "        .set_index(\"DATE\")\n",
        "    )\n",
        "\n",
        "    # Ensure numeric types\n",
        "    for col in [TARGET_SERIES] + MACRO_COLS:\n",
        "        df[col] = pd.to_numeric(df[col], errors=\"coerce\")\n",
        "    df = df.dropna(subset=[TARGET_SERIES])\n",
        "\n",
        "    # Business-day EUR_NOK (truth / aggregation base)\n",
        "    S_b = df[TARGET_SERIES].asfreq(\"B\").ffill().astype(float)\n",
        "    S_b.name = TARGET_SERIES\n",
        "\n",
        "    # Daily DF_d (calendar days, forward-filled)\n",
        "    full_idx = pd.date_range(df.index.min(), df.index.max(), freq=\"D\")\n",
        "    DF_d = df.reindex(full_idx).ffill()\n",
        "    DF_d.index.name = \"DATE\"\n",
        "\n",
        "    return S_b, DF_d\n",
        "\n",
        "def last_trading_day(S_b: pd.Series, start: pd.Timestamp, end: pd.Timestamp) -> Optional[pd.Timestamp]:\n",
        "    \"\"\"Return the last business day in [start, end].\"\"\"\n",
        "    sl = S_b.loc[start:end]\n",
        "    return sl.index[-1] if not sl.empty else None\n",
        "\n",
        "# -----------------------------\n",
        "# Feature engineering (multivariate lags)\n",
        "# -----------------------------\n",
        "def make_lag_matrix(df_hist: pd.DataFrame, max_lags: int) -> Tuple[np.ndarray, np.ndarray]:\n",
        "    \"\"\"\n",
        "    Build X, y_target for one-step ahead daily forecasting.\n",
        "\n",
        "    For each t:\n",
        "      X_t = [EUR_NOK_{t-1..t-L}, Q_{t-1..t-L}, d_pi_{t-1..t-L}, dI_t_{t-1..t-L}]\n",
        "      y_target = EUR_NOK_t\n",
        "    \"\"\"\n",
        "    work = df_hist[[TARGET_SERIES] + MACRO_COLS].copy()\n",
        "    lag_cols: List[str] = []\n",
        "\n",
        "    for var in [TARGET_SERIES] + MACRO_COLS:\n",
        "        for k in range(1, max_lags + 1):\n",
        "            name = f\"{var}_lag{k}\"\n",
        "            work[name] = work[var].shift(k)\n",
        "            lag_cols.append(name)\n",
        "\n",
        "    work = work.dropna()\n",
        "    X = work[lag_cols].values\n",
        "    y_target = work[TARGET_SERIES].values\n",
        "    return X, y_target\n",
        "\n",
        "# -----------------------------\n",
        "# Gradient Boosting one-step model\n",
        "# -----------------------------\n",
        "def fit_gb_one_step(df_hist_daily: pd.DataFrame) -> GradientBoostingRegressor:\n",
        "    \"\"\"Fit Gradient Boosting for one-step ahead daily prediction using lagged target + lagged macros.\"\"\"\n",
        "    X, y_target = make_lag_matrix(df_hist_daily, CFG.max_lags)\n",
        "    model = GradientBoostingRegressor(\n",
        "        n_estimators=CFG.n_estimators,\n",
        "        learning_rate=CFG.learning_rate,\n",
        "        max_depth=CFG.max_depth,\n",
        "        subsample=CFG.subsample,\n",
        "        min_samples_leaf=CFG.min_samples_leaf,\n",
        "        random_state=CFG.random_state,\n",
        "    )\n",
        "    model.fit(X, y_target)\n",
        "    return model\n",
        "\n",
        "def recursive_daily_forecast(model: GradientBoostingRegressor, df_hist_daily: pd.DataFrame, H: int) -> pd.Series:\n",
        "    \"\"\"\n",
        "    Produce H daily forecasts recursively.\n",
        "\n",
        "    Anti-leakage rule:\n",
        "      - Macros are treated as past-only covariates.\n",
        "      - During recursion we freeze macro values at their last observed level.\n",
        "    \"\"\"\n",
        "    hist = df_hist_daily[[TARGET_SERIES] + MACRO_COLS].copy()\n",
        "    last_macros = hist[MACRO_COLS].iloc[-1].to_dict()\n",
        "\n",
        "    preds = []\n",
        "    for _ in range(H):\n",
        "        if len(hist) < CFG.max_lags:\n",
        "            raise ValueError(\"Not enough history for lag features.\")\n",
        "\n",
        "        row_feats = []\n",
        "        for var in [TARGET_SERIES] + MACRO_COLS:\n",
        "            lags = hist[var].iloc[-CFG.max_lags:][::-1].values\n",
        "            row_feats.extend(lags.tolist())\n",
        "\n",
        "        x = np.array(row_feats, dtype=float).reshape(1, -1)\n",
        "        yhat = float(model.predict(x)[0])\n",
        "        preds.append(yhat)\n",
        "\n",
        "        new_row = {TARGET_SERIES: yhat}\n",
        "        for mc in MACRO_COLS:\n",
        "            new_row[mc] = last_macros[mc]\n",
        "\n",
        "        hist = pd.concat(\n",
        "            [hist, pd.DataFrame([new_row], index=[hist.index[-1] + pd.Timedelta(days=1)])]\n",
        "        )\n",
        "\n",
        "    return pd.Series(preds)\n",
        "\n",
        "# -----------------------------\n",
        "# Quarterly walk-forward using GB + past macros\n",
        "# -----------------------------\n",
        "def walk_forward_gb_quarterly_pastcov(S_b: pd.Series, DF_d: pd.DataFrame) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    For each calendar quarter q:\n",
        "      - cut at last business day of previous quarter\n",
        "      - fit GB on daily history up to cut (EUR_NOK + macros)\n",
        "      - recursively forecast full next quarter at daily frequency\n",
        "      - aggregate to business-day quarterly mean and compare to truth\n",
        "    \"\"\"\n",
        "    first_q = pd.Period(S_b.index.min(), freq=CFG.q_freq)\n",
        "    last_q  = pd.Period(S_b.index.max(), freq=CFG.q_freq)\n",
        "    quarters = pd.period_range(first_q, last_q, freq=CFG.q_freq)\n",
        "\n",
        "    rows: Dict = {}\n",
        "    dropped: Dict[str, str] = {}\n",
        "\n",
        "    for q in quarters:\n",
        "        prev_q = q - 1\n",
        "        q_start, q_end = q.start_time, q.end_time\n",
        "        prev_start, prev_end = prev_q.start_time, prev_q.end_time\n",
        "\n",
        "        cut = last_trading_day(S_b, prev_start, prev_end)\n",
        "        if cut is None:\n",
        "            dropped[str(q)] = \"no_cut_in_prev_quarter\"\n",
        "            continue\n",
        "\n",
        "        hist_df = DF_d.loc[:cut]\n",
        "        if hist_df.shape[0] < CFG.min_hist_days:\n",
        "            dropped[str(q)] = f\"hist<{CFG.min_hist_days}\"\n",
        "            continue\n",
        "\n",
        "        idx_q_b = S_b.index[(S_b.index >= q_start) & (S_b.index <= q_end)]\n",
        "        if idx_q_b.size < 1:\n",
        "            dropped[str(q)] = \"no_bdays_in_quarter\"\n",
        "            continue\n",
        "        y_true = float(S_b.loc[idx_q_b].mean())\n",
        "\n",
        "        H = (q_end.date() - q_start.date()).days + 1\n",
        "        if H <= 0 or H > CFG.max_horizon:\n",
        "            dropped[str(q)] = f\"horizon_invalid(H={H})\"\n",
        "            continue\n",
        "\n",
        "        model = fit_gb_one_step(hist_df)\n",
        "        pf = recursive_daily_forecast(model, hist_df, H)\n",
        "\n",
        "        f_idx = pd.date_range(cut + pd.Timedelta(days=1), periods=H, freq=\"D\")\n",
        "        pred_daily = pd.Series(pf.values, index=f_idx, name=\"point\")\n",
        "\n",
        "        pred_b = pred_daily.reindex(idx_q_b, method=None)\n",
        "        if pred_b.isna().all():\n",
        "            dropped[str(q)] = \"no_overlap_pred_B_days\"\n",
        "            continue\n",
        "        y_pred = float(pred_b.dropna().mean())\n",
        "\n",
        "        rows[str(q)] = {\"quarter\": q, \"cut\": cut, \"y_true\": y_true, \"y_pred\": y_pred}\n",
        "\n",
        "    df = pd.DataFrame.from_dict(rows, orient=\"index\")\n",
        "    if not df.empty:\n",
        "        df = df.set_index(\"quarter\").sort_index()\n",
        "\n",
        "    if CFG.verbose and dropped:\n",
        "        miss = [str(q) for q in quarters if q not in df.index]\n",
        "        if miss:\n",
        "            print(\"\\nDropped quarters and reasons:\")\n",
        "            for qq in miss:\n",
        "                print(f\"  {qq}: {dropped.get(qq, 'unknown')}\")\n",
        "    return df\n",
        "\n",
        "# -----------------------------\n",
        "# Evaluation (level + direction)\n",
        "# -----------------------------\n",
        "def evaluate(eval_df: pd.DataFrame) -> pd.DataFrame:\n",
        "    df = eval_df.copy()\n",
        "    df[\"err\"] = df[\"y_true\"] - df[\"y_pred\"]\n",
        "    core = df.dropna(subset=[\"y_true\", \"y_pred\"]).copy()\n",
        "\n",
        "    n_obs = int(len(core))\n",
        "    rmse = float(np.sqrt(np.mean(np.square(core[\"err\"])))) if n_obs else np.nan\n",
        "    mae  = float(mean_absolute_error(core[\"y_true\"], core[\"y_pred\"])) if n_obs else np.nan\n",
        "\n",
        "    core[\"y_prev\"] = core[\"y_true\"].shift(1)\n",
        "    mask = core[\"y_prev\"].notna()\n",
        "    dir_true = np.sign(core.loc[mask, \"y_true\"] - core.loc[mask, \"y_prev\"])\n",
        "    dir_pred = np.sign(core.loc[mask, \"y_pred\"] - core.loc[mask, \"y_prev\"])\n",
        "    hits = int((dir_true.values == dir_pred.values).sum())\n",
        "    total = int(mask.sum())\n",
        "    hit_rate = (hits / total) if total else np.nan\n",
        "\n",
        "    print(\"\\n=== Model performance (quarterly mean, EUR/NOK – GB past macro covariates) ===\")\n",
        "    print(f\"Observations: {n_obs}\")\n",
        "    print(f\"RMSE (level): {rmse:.6f}\")\n",
        "    print(f\"MAE  (level): {mae:.6f}\")\n",
        "    if total:\n",
        "        print(f\"Directional accuracy: {hits}/{total} ({hit_rate*100:.1f}%)\")\n",
        "\n",
        "    return core\n",
        "\n",
        "# -----------------------------\n",
        "# Diebold–Mariano (vs Random Walk)\n",
        "# -----------------------------\n",
        "def _normal_cdf(z: float) -> float:\n",
        "    return 0.5 * (1.0 + math.erf(z / math.sqrt(2.0)))\n",
        "\n",
        "def dm_test(y_true: pd.Series, y_model: pd.Series, y_rw: pd.Series, h: int = 1, loss: str = \"mse\") -> Tuple[float, float]:\n",
        "    df = pd.concat({\"y\": y_true, \"m\": y_model, \"rw\": y_rw}, axis=1).dropna()\n",
        "    if df.empty or len(df) < 5:\n",
        "        return float(\"nan\"), float(\"nan\")\n",
        "\n",
        "    e_m = df[\"y\"] - df[\"m\"]\n",
        "    e_r = df[\"y\"] - df[\"rw\"]\n",
        "    d = np.abs(e_m) - np.abs(e_r) if loss.lower() == \"mae\" else (e_m**2) - (e_r**2)\n",
        "\n",
        "    N = int(len(d))\n",
        "    d_mean = float(d.mean())\n",
        "    gamma0 = float(np.var(d, ddof=1)) if N > 1 else 0.0\n",
        "    var_bar = gamma0 / N\n",
        "\n",
        "    if h > 1 and N > 2:\n",
        "        for k in range(1, min(h - 1, N - 1) + 1):\n",
        "            w_k = 1.0 - k / h\n",
        "            cov_k = float(np.cov(d[k:], d[:-k], ddof=1)[0, 1])\n",
        "            var_bar += 2.0 * w_k * cov_k / N\n",
        "\n",
        "    if var_bar <= 0 or not np.isfinite(var_bar):\n",
        "        return float(\"nan\"), float(\"nan\")\n",
        "\n",
        "    dm_stat = d_mean / math.sqrt(var_bar)\n",
        "    p_val = 2.0 * (1.0 - _normal_cdf(abs(dm_stat)))\n",
        "    return dm_stat, p_val\n",
        "\n",
        "def dm_against_random_walk(eval_df: pd.DataFrame, loss: str = \"mse\", h: int = 1) -> None:\n",
        "    df = eval_df.copy()\n",
        "    df[\"rw_pred\"] = df[\"y_true\"].shift(1)\n",
        "    dm_stat, p_val = dm_test(df[\"y_true\"], df[\"y_pred\"], df[\"rw_pred\"], h=h, loss=loss)\n",
        "    print(\"\\n=== Diebold–Mariano vs Random Walk (GB past macro covariates, quarterly) ===\")\n",
        "    print(f\"Loss: {loss.upper()} | horizon h={h}\")\n",
        "    print(f\"DM-statistic: {dm_stat:.4f}\" if np.isfinite(dm_stat) else \"DM-statistic: nan\")\n",
        "    print(f\"p-value     : {p_val:.4f}\" if np.isfinite(p_val) else \"p-value     : nan\")\n",
        "\n",
        "# -----------------------------\n",
        "# Plot (no bands)\n",
        "# -----------------------------\n",
        "def plot_quarterly_simple(eval_df: pd.DataFrame, png_path: str, pdf_path: str):\n",
        "    if eval_df.empty:\n",
        "        print(\"Nothing to plot.\")\n",
        "        return\n",
        "\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    x = eval_df.index.to_timestamp() if isinstance(eval_df.index, pd.PeriodIndex) else eval_df.index\n",
        "\n",
        "    plt.plot(x, eval_df[\"y_true\"], color=\"black\", label=\"Actual (quarterly mean, B-days)\")\n",
        "    plt.plot(x, eval_df[\"y_pred\"], color=\"tab:blue\", linestyle=\"--\",\n",
        "             label=\"Forecast (Gradient Boosting, past macro covariates)\")\n",
        "\n",
        "    plt.title(\"Gradient Boosting Forecast vs Actual (Quarterly Mean, EUR/NOK – past macro covariates)\")\n",
        "    plt.xlabel(\"Quarter\")\n",
        "    plt.ylabel(\"Level\")\n",
        "    plt.legend()\n",
        "    plt.grid(True, alpha=0.3)\n",
        "    plt.tight_layout()\n",
        "\n",
        "    plt.savefig(png_path, dpi=300, bbox_inches=\"tight\")\n",
        "    plt.savefig(pdf_path, bbox_inches=\"tight\")\n",
        "    plt.show()\n",
        "    print(f\"Saved: {png_path}\")\n",
        "    print(f\"Saved: {pdf_path}\")\n",
        "\n",
        "# -----------------------------\n",
        "# Main\n",
        "# -----------------------------\n",
        "def main():\n",
        "    S_b, DF_d = load_series(CFG.url)\n",
        "    if CFG.verbose:\n",
        "        print(f\"Data (B): {S_b.index.min().date()} → {S_b.index.max().date()} | n={len(S_b)}\")\n",
        "        print(f\"Data (D): {DF_d.index.min().date()} → {DF_d.index.max().date()} | n={len(DF_d)}\")\n",
        "        print(f\"Columns (DF_d): {list(DF_d.columns)}\")\n",
        "\n",
        "    df_eval = walk_forward_gb_quarterly_pastcov(S_b, DF_d)\n",
        "    eval_df = evaluate(df_eval)\n",
        "\n",
        "    dm_against_random_walk(eval_df, loss=\"mse\", h=1)\n",
        "\n",
        "    plot_quarterly_simple(eval_df, CFG.fig_png, CFG.fig_pdf)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "id": "t0qVvP4tTIN1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## GB_Fx-Monthly_panel\n"
      ],
      "metadata": {
        "id": "geEMxM2XTJHL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================================\n",
        "# Gradient Boosting – EUR/NOK walk-forward (monthly, levels) with daily panel + macro covariates\n",
        "# Cross-learning analogue for GB:\n",
        "#   - Target: EUR_NOK (single series)\n",
        "#   - Panel predictors: Brent, VIX, StoxEurope, SP500, OSEBX, OBX_Energy + EUR_NOK lags\n",
        "#   - Macros: Q, d_pi, dI_t as past-only covariates\n",
        "#   - Data: daily (calendar days), forward-filled\n",
        "#   - Cut: last business day of previous month (based on EUR_NOK B-days)\n",
        "#   - Forecast: recursive daily next-month -> aggregate to monthly mean over business days\n",
        "#   - No future covariate paths -> all non-target predictors frozen at last observed level\n",
        "#   - Metrics: Observations, RMSE, MAE, Directional accuracy\n",
        "#   - Test: Diebold–Mariano vs Random Walk (MSE, h=1)\n",
        "#   - Plot: Actual (black) vs Forecast (blue dashed), no intervals\n",
        "# =========================================\n",
        "\n",
        "!pip -q install pandas numpy scikit-learn matplotlib requests certifi\n",
        "\n",
        "from __future__ import annotations\n",
        "import io, time, math\n",
        "from dataclasses import dataclass\n",
        "from typing import Optional, Tuple, Dict, List\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import requests, certifi\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "\n",
        "# -----------------------------\n",
        "# Configuration\n",
        "# -----------------------------\n",
        "@dataclass\n",
        "class Config:\n",
        "    url: str = (\n",
        "        \"https://raw.githubusercontent.com/bredeespelid/\"\n",
        "        \"Data_MasterOppgave/refs/heads/main/Variables/All_Variables/variables_daily.csv\"\n",
        "    )\n",
        "    m_freq: str = \"M\"          # monthly evaluation\n",
        "    min_hist_days: int = 400   # more history for stable GB with many predictors\n",
        "    max_lags: int = 20         # number of daily lags for each predictor\n",
        "    max_horizon: int = 64      # must exceed longest month (~31 days)\n",
        "\n",
        "    # Gradient Boosting hyperparameters\n",
        "    n_estimators: int = 1500\n",
        "    learning_rate: float = 0.03\n",
        "    max_depth: int = 3\n",
        "    subsample: float = 0.8\n",
        "    min_samples_leaf: int = 2\n",
        "    random_state: int = 42\n",
        "\n",
        "    retries: int = 3\n",
        "    timeout: int = 60\n",
        "    verbose: bool = True\n",
        "    fig_png: str = \"GB_M_daily_panel_pastcov.png\"\n",
        "    fig_pdf: str = \"GB_M_daily_panel_pastcov.pdf\"\n",
        "\n",
        "CFG = Config()\n",
        "\n",
        "TARGET_SERIES = \"EUR_NOK\"\n",
        "PANEL_SERIES = [\n",
        "    \"EUR_NOK\",\n",
        "    \"Brent\",\n",
        "    \"VIX\",\n",
        "    \"StoxEurope\",\n",
        "    \"SP500\",\n",
        "    \"OSEBX\",\n",
        "    \"OBX_Energy\",\n",
        "]\n",
        "MACRO_COLS = [\"Q\", \"d_pi\", \"dI_t\"]\n",
        "\n",
        "ALL_PREDICTORS = PANEL_SERIES + MACRO_COLS  # all used as lagged predictors\n",
        "\n",
        "# -----------------------------\n",
        "# Download helper\n",
        "# -----------------------------\n",
        "def download_csv_text(url: str, retries: int, timeout: int) -> str:\n",
        "    \"\"\"Download CSV with simple retry/backoff.\"\"\"\n",
        "    last_err = None\n",
        "    for k in range(1, retries + 1):\n",
        "        try:\n",
        "            r = requests.get(url, timeout=timeout, verify=certifi.where())\n",
        "            r.raise_for_status()\n",
        "            return r.text\n",
        "        except Exception as e:\n",
        "            last_err = e\n",
        "            if k < retries:\n",
        "                wait = 1.5 * k\n",
        "                print(f\"[warning] Download failed (try {k}/{retries}): {e}. Retrying in {wait:.1f}s ...\")\n",
        "                time.sleep(wait)\n",
        "    raise RuntimeError(f\"Download failed: {last_err}\")\n",
        "\n",
        "# -----------------------------\n",
        "# Data loading: daily wide DF + EUR_NOK business-day series\n",
        "# -----------------------------\n",
        "def load_series(url: str) -> Tuple[pd.Series, pd.DataFrame]:\n",
        "    \"\"\"\n",
        "    Load daily CSV. Expected columns:\n",
        "      Date, EUR_NOK, Q, d_pi, dI_t, Brent, VIX, StoxEurope, SP500, OSEBX, OBX_Energy\n",
        "\n",
        "    Returns:\n",
        "      S_b  : EUR_NOK on business days (B) with ffill (for cuts and monthly ground truth)\n",
        "      DF_d : daily (D) wide DataFrame with PANEL_SERIES + MACRO_COLS\n",
        "             calendar days, forward-filled\n",
        "    \"\"\"\n",
        "    text = download_csv_text(url, CFG.retries, CFG.timeout)\n",
        "    raw = pd.read_csv(io.StringIO(text))\n",
        "\n",
        "    required_cols = {\"Date\"} | set(ALL_PREDICTORS)\n",
        "    missing = required_cols - set(raw.columns)\n",
        "    if missing:\n",
        "        raise ValueError(f\"Missing columns in CSV: {missing}. Got: {list(raw.columns)}\")\n",
        "\n",
        "    df = (\n",
        "        raw[list(required_cols)]\n",
        "        .rename(columns={\"Date\": \"DATE\"})\n",
        "        .assign(DATE=lambda x: pd.to_datetime(x[\"DATE\"], errors=\"coerce\"))\n",
        "        .dropna(subset=[\"DATE\", TARGET_SERIES])\n",
        "        .sort_values(\"DATE\")\n",
        "        .set_index(\"DATE\")\n",
        "    )\n",
        "\n",
        "    # Ensure numeric types\n",
        "    for col in ALL_PREDICTORS:\n",
        "        df[col] = pd.to_numeric(df[col], errors=\"coerce\")\n",
        "    df = df.dropna(subset=[TARGET_SERIES])\n",
        "\n",
        "    # Business-day EUR_NOK (truth/aggregation base)\n",
        "    S_b = df[TARGET_SERIES].asfreq(\"B\").ffill().astype(float)\n",
        "    S_b.name = TARGET_SERIES\n",
        "\n",
        "    # Daily wide DF_d (calendar days, forward-filled)\n",
        "    full_idx = pd.date_range(df.index.min(), df.index.max(), freq=\"D\")\n",
        "    DF_d = df.reindex(full_idx).ffill()\n",
        "    DF_d.index.name = \"DATE\"\n",
        "\n",
        "    return S_b, DF_d\n",
        "\n",
        "def last_trading_day(S_b: pd.Series, start: pd.Timestamp, end: pd.Timestamp) -> Optional[pd.Timestamp]:\n",
        "    \"\"\"Return the last business day in [start, end].\"\"\"\n",
        "    sl = S_b.loc[start:end]\n",
        "    return sl.index[-1] if not sl.empty else None\n",
        "\n",
        "# -----------------------------\n",
        "# Feature engineering: multivariate lag matrix\n",
        "# -----------------------------\n",
        "def make_lag_matrix(\n",
        "    df_hist: pd.DataFrame,\n",
        "    predictors: List[str],\n",
        "    max_lags: int\n",
        ") -> Tuple[np.ndarray, np.ndarray, List[str]]:\n",
        "    \"\"\"\n",
        "    Build X, y for one-step ahead daily forecasting of EUR_NOK.\n",
        "\n",
        "    For each t:\n",
        "      X_t = stacked lags of all predictors (past-only):\n",
        "        [pred1_{t-1..t-L}, pred2_{t-1..t-L}, ...]\n",
        "      y_t = EUR_NOK_t\n",
        "    \"\"\"\n",
        "    work = df_hist[predictors].copy()\n",
        "    lag_cols: List[str] = []\n",
        "\n",
        "    for var in predictors:\n",
        "        for k in range(1, max_lags + 1):\n",
        "            name = f\"{var}_lag{k}\"\n",
        "            work[name] = work[var].shift(k)\n",
        "            lag_cols.append(name)\n",
        "\n",
        "    work = work.dropna()\n",
        "    X = work[lag_cols].values\n",
        "    y = work[TARGET_SERIES].values\n",
        "    return X, y, lag_cols\n",
        "\n",
        "# -----------------------------\n",
        "# Gradient Boosting one-step model\n",
        "# -----------------------------\n",
        "def fit_gb_one_step(df_hist_daily: pd.DataFrame) -> Tuple[GradientBoostingRegressor, List[str]]:\n",
        "    \"\"\"Fit GB for one-step daily prediction using lags of panel + macros.\"\"\"\n",
        "    X, y, lag_cols = make_lag_matrix(df_hist_daily, ALL_PREDICTORS, CFG.max_lags)\n",
        "\n",
        "    model = GradientBoostingRegressor(\n",
        "        n_estimators=CFG.n_estimators,\n",
        "        learning_rate=CFG.learning_rate,\n",
        "        max_depth=CFG.max_depth,\n",
        "        subsample=CFG.subsample,\n",
        "        min_samples_leaf=CFG.min_samples_leaf,\n",
        "        random_state=CFG.random_state,\n",
        "    )\n",
        "    model.fit(X, y)\n",
        "    return model, lag_cols\n",
        "\n",
        "def recursive_daily_forecast(\n",
        "    model: GradientBoostingRegressor,\n",
        "    df_hist_daily: pd.DataFrame,\n",
        "    H: int,\n",
        ") -> pd.Series:\n",
        "    \"\"\"\n",
        "    Produce H daily forecasts recursively.\n",
        "\n",
        "    Anti-leakage rule:\n",
        "      - Panel series and macros are treated as past-only covariates.\n",
        "      - During recursion all non-target predictors are frozen at their last observed level.\n",
        "    \"\"\"\n",
        "    hist = df_hist_daily[ALL_PREDICTORS].copy()\n",
        "\n",
        "    # Last observed levels for all predictors (frozen), target updated each step\n",
        "    last_vals = hist.iloc[-1].to_dict()\n",
        "\n",
        "    preds = []\n",
        "    for _ in range(H):\n",
        "        if len(hist) < CFG.max_lags:\n",
        "            raise ValueError(\"Not enough history for lag features.\")\n",
        "\n",
        "        row_feats = []\n",
        "        for var in ALL_PREDICTORS:\n",
        "            lags = hist[var].iloc[-CFG.max_lags:][::-1].values\n",
        "            row_feats.extend(lags.tolist())\n",
        "\n",
        "        x = np.array(row_feats, dtype=float).reshape(1, -1)\n",
        "        yhat = float(model.predict(x)[0])\n",
        "        preds.append(yhat)\n",
        "\n",
        "        new_row = last_vals.copy()\n",
        "        new_row[TARGET_SERIES] = yhat\n",
        "        new_idx = hist.index[-1] + pd.Timedelta(days=1)\n",
        "\n",
        "        hist = pd.concat([hist, pd.DataFrame([new_row], index=[new_idx])])\n",
        "\n",
        "    return pd.Series(preds)\n",
        "\n",
        "# -----------------------------\n",
        "# Monthly walk-forward using GB + panel/macros (past-only)\n",
        "# -----------------------------\n",
        "def walk_forward_gb_monthly_panel_pastcov(S_b: pd.Series, DF_d: pd.DataFrame) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    For each calendar month m:\n",
        "      - cut at last business day of previous month\n",
        "      - fit GB on daily history up to cut (EUR_NOK + panel + macros, lagged)\n",
        "      - recursively forecast full next month at daily frequency\n",
        "      - aggregate to business-day monthly mean and compare to truth\n",
        "    \"\"\"\n",
        "    first_m = pd.Period(S_b.index.min(), freq=CFG.m_freq)\n",
        "    last_m  = pd.Period(S_b.index.max(), freq=CFG.m_freq)\n",
        "    months = pd.period_range(first_m, last_m, freq=CFG.m_freq)\n",
        "\n",
        "    rows: Dict = {}\n",
        "    dropped: Dict[str, str] = {}\n",
        "\n",
        "    for m in months:\n",
        "        prev_m = m - 1\n",
        "        m_start, m_end = m.start_time, m.end_time\n",
        "        prev_start, prev_end = prev_m.start_time, prev_m.end_time\n",
        "\n",
        "        cut = last_trading_day(S_b, prev_start, prev_end)\n",
        "        if cut is None:\n",
        "            dropped[str(m)] = \"no_cut_in_prev_month\"\n",
        "            continue\n",
        "\n",
        "        hist_df = DF_d.loc[:cut]\n",
        "        if hist_df.shape[0] < CFG.min_hist_days:\n",
        "            dropped[str(m)] = f\"hist<{CFG.min_hist_days}\"\n",
        "            continue\n",
        "\n",
        "        idx_m_b = S_b.index[(S_b.index >= m_start) & (S_b.index <= m_end)]\n",
        "        if idx_m_b.size < 1:\n",
        "            dropped[str(m)] = \"no_bdays_in_month\"\n",
        "            continue\n",
        "        y_true = float(S_b.loc[idx_m_b].mean())\n",
        "\n",
        "        H = (m_end.date() - m_start.date()).days + 1\n",
        "        if H <= 0 or H > CFG.max_horizon:\n",
        "            dropped[str(m)] = f\"horizon_invalid(H={H})\"\n",
        "            continue\n",
        "\n",
        "        model, _ = fit_gb_one_step(hist_df)\n",
        "        pf = recursive_daily_forecast(model, hist_df, H)\n",
        "\n",
        "        f_idx = pd.date_range(cut + pd.Timedelta(days=1), periods=H, freq=\"D\")\n",
        "        pred_daily = pd.Series(pf.values, index=f_idx, name=\"point\")\n",
        "\n",
        "        pred_b = pred_daily.reindex(idx_m_b, method=None)\n",
        "        if pred_b.isna().all():\n",
        "            dropped[str(m)] = \"no_overlap_pred_B_days\"\n",
        "            continue\n",
        "        y_pred = float(pred_b.dropna().mean())\n",
        "\n",
        "        rows[str(m)] = {\"month\": m, \"cut\": cut, \"y_true\": y_true, \"y_pred\": y_pred}\n",
        "\n",
        "    df = pd.DataFrame.from_dict(rows, orient=\"index\")\n",
        "    if not df.empty:\n",
        "        df = df.set_index(\"month\").sort_index()\n",
        "\n",
        "    if CFG.verbose and dropped:\n",
        "        miss = [str(m) for m in months if m not in df.index]\n",
        "        if miss:\n",
        "            print(\"\\nDropped months and reasons:\")\n",
        "            for mm in miss:\n",
        "                print(f\"  {mm}: {dropped.get(mm, 'unknown')}\")\n",
        "    return df\n",
        "\n",
        "# -----------------------------\n",
        "# Evaluation (level + direction)\n",
        "# -----------------------------\n",
        "def evaluate(eval_df: pd.DataFrame) -> pd.DataFrame:\n",
        "    df = eval_df.copy()\n",
        "    df[\"err\"] = df[\"y_true\"] - df[\"y_pred\"]\n",
        "    core = df.dropna(subset=[\"y_true\", \"y_pred\"]).copy()\n",
        "\n",
        "    n_obs = int(len(core))\n",
        "    rmse = float(np.sqrt(np.mean(np.square(core[\"err\"])))) if n_obs else np.nan\n",
        "    mae  = float(mean_absolute_error(core[\"y_true\"], core[\"y_pred\"])) if n_obs else np.nan\n",
        "\n",
        "    core[\"y_prev\"] = core[\"y_true\"].shift(1)\n",
        "    mask = core[\"y_prev\"].notna()\n",
        "    dir_true = np.sign(core.loc[mask, \"y_true\"] - core.loc[mask, \"y_prev\"])\n",
        "    dir_pred = np.sign(core.loc[mask, \"y_pred\"] - core.loc[mask, \"y_prev\"])\n",
        "    hits = int((dir_true.values == dir_pred.values).sum())\n",
        "    total = int(mask.sum())\n",
        "    hit_rate = (hits / total) if total else np.nan\n",
        "\n",
        "    print(\"\\n=== Model performance (monthly mean, EUR/NOK – GB panel + past macro covariates) ===\")\n",
        "    print(f\"Observations: {n_obs}\")\n",
        "    print(f\"RMSE (level): {rmse:.6f}\")\n",
        "    print(f\"MAE  (level): {mae:.6f}\")\n",
        "    if total:\n",
        "        print(f\"Directional accuracy: {hits}/{total} ({hit_rate*100:.1f}%)\")\n",
        "\n",
        "    return core\n",
        "\n",
        "# -----------------------------\n",
        "# Diebold–Mariano (vs Random Walk)\n",
        "# -----------------------------\n",
        "def _normal_cdf(z: float) -> float:\n",
        "    return 0.5 * (1.0 + math.erf(z / math.sqrt(2.0)))\n",
        "\n",
        "def dm_test(y_true: pd.Series, y_model: pd.Series, y_rw: pd.Series, h: int = 1, loss: str = \"mse\") -> Tuple[float, float]:\n",
        "    df = pd.concat({\"y\": y_true, \"m\": y_model, \"rw\": y_rw}, axis=1).dropna()\n",
        "    if df.empty or len(df) < 5:\n",
        "        return float(\"nan\"), float(\"nan\")\n",
        "\n",
        "    e_m = df[\"y\"] - df[\"m\"]\n",
        "    e_r = df[\"y\"] - df[\"rw\"]\n",
        "    d = np.abs(e_m) - np.abs(e_r) if loss.lower() == \"mae\" else (e_m**2) - (e_r**2)\n",
        "\n",
        "    N = int(len(d))\n",
        "    d_mean = float(d.mean())\n",
        "    gamma0 = float(np.var(d, ddof=1)) if N > 1 else 0.0\n",
        "    var_bar = gamma0 / N\n",
        "\n",
        "    if h > 1 and N > 2:\n",
        "        for k in range(1, min(h - 1, N - 1) + 1):\n",
        "            w_k = 1.0 - k / h\n",
        "            cov_k = float(np.cov(d[k:], d[:-k], ddof=1)[0, 1])\n",
        "            var_bar += 2.0 * w_k * cov_k / N\n",
        "\n",
        "    if var_bar <= 0 or not np.isfinite(var_bar):\n",
        "        return float(\"nan\"), float(\"nan\")\n",
        "\n",
        "    dm_stat = d_mean / math.sqrt(var_bar)\n",
        "    p_val = 2.0 * (1.0 - _normal_cdf(abs(dm_stat)))\n",
        "    return dm_stat, p_val\n",
        "\n",
        "def dm_against_random_walk(eval_df: pd.DataFrame, loss: str = \"mse\", h: int = 1) -> None:\n",
        "    df = eval_df.copy()\n",
        "    df[\"rw_pred\"] = df[\"y_true\"].shift(1)\n",
        "    dm_stat, p_val = dm_test(df[\"y_true\"], df[\"y_pred\"], df[\"rw_pred\"], h=h, loss=loss)\n",
        "    print(\"\\n=== Diebold–Mariano vs Random Walk (GB panel setup, monthly) ===\")\n",
        "    print(f\"Loss: {loss.upper()} | horizon h={h}\")\n",
        "    print(f\"DM-statistic: {dm_stat:.4f}\" if np.isfinite(dm_stat) else \"DM-statistic: nan\")\n",
        "    print(f\"p-value     : {p_val:.4f}\" if np.isfinite(p_val) else \"p-value     : nan\")\n",
        "\n",
        "# -----------------------------\n",
        "# Plot (no bands)\n",
        "# -----------------------------\n",
        "def plot_monthly_simple(eval_df: pd.DataFrame, png_path: str, pdf_path: str):\n",
        "    if eval_df.empty:\n",
        "        print(\"Nothing to plot.\")\n",
        "        return\n",
        "\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    x = eval_df.index.to_timestamp() if isinstance(eval_df.index, pd.PeriodIndex) else eval_df.index\n",
        "\n",
        "    plt.plot(x, eval_df[\"y_true\"], color=\"black\", label=\"Actual (monthly mean, B-days)\")\n",
        "    plt.plot(x, eval_df[\"y_pred\"], color=\"tab:blue\", linestyle=\"--\",\n",
        "             label=\"Forecast (Gradient Boosting, panel + past macro covariates)\")\n",
        "\n",
        "    plt.title(\"Gradient Boosting Forecast vs Actual (Monthly Mean, EUR/NOK – panel setup)\")\n",
        "    plt.xlabel(\"Month\")\n",
        "    plt.ylabel(\"EUR/NOK level\")\n",
        "    plt.legend()\n",
        "    plt.grid(True, alpha=0.3)\n",
        "    plt.tight_layout()\n",
        "\n",
        "    plt.savefig(png_path, dpi=300, bbox_inches=\"tight\")\n",
        "    plt.savefig(pdf_path, bbox_inches=\"tight\")\n",
        "    plt.show()\n",
        "    print(f\"Saved: {png_path}\")\n",
        "    print(f\"Saved: {pdf_path}\")\n",
        "\n",
        "# -----------------------------\n",
        "# Main\n",
        "# -----------------------------\n",
        "def main():\n",
        "    S_b, DF_d = load_series(CFG.url)\n",
        "    if CFG.verbose:\n",
        "        print(f\"Data (B): {S_b.index.min().date()} → {S_b.index.max().date()} | n={len(S_b)}\")\n",
        "        print(f\"Data (D): {DF_d.index.min().date()} → {DF_d.index.max().date()} | n={len(DF_d)}\")\n",
        "        print(f\"Columns (DF_d): {list(DF_d.columns)}\")\n",
        "\n",
        "    df_eval = walk_forward_gb_monthly_panel_pastcov(S_b, DF_d)\n",
        "    eval_df = evaluate(df_eval)\n",
        "\n",
        "    dm_against_random_walk(eval_df, loss=\"mse\", h=1)\n",
        "\n",
        "    plot_monthly_simple(eval_df, CFG.fig_png, CFG.fig_pdf)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "id": "aebyhGtFTNZ4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## GB_Fx-Quarterly_panel\n"
      ],
      "metadata": {
        "id": "kc29tyXSTMX2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================================\n",
        "# Gradient Boosting – EUR/NOK walk-forward (quarterly, levels) with daily panel + macro covariates\n",
        "# Cross-learning analogue for GB:\n",
        "#   - Target: EUR_NOK (single series)\n",
        "#   - Panel predictors: Brent, VIX, StoxEurope, SP500, OSEBX, OBX_Energy + EUR_NOK lags\n",
        "#   - Macros: Q, d_pi, dI_t as past-only covariates\n",
        "#   - Data: daily (calendar days), forward-filled\n",
        "#   - Cut: last business day of previous quarter (based on EUR_NOK B-days)\n",
        "#   - Forecast: recursive daily next-quarter -> aggregate to quarterly mean over business days\n",
        "#   - No future covariate paths -> all non-target predictors frozen at last observed level\n",
        "#   - Metrics: Observations, RMSE, MAE, Directional accuracy\n",
        "#   - Test: Diebold–Mariano vs Random Walk (MSE, h=1)\n",
        "#   - Plot: Actual (black) vs Forecast (blue dashed), no intervals\n",
        "# =========================================\n",
        "\n",
        "!pip -q install pandas numpy scikit-learn matplotlib requests certifi\n",
        "\n",
        "from __future__ import annotations\n",
        "import io, time, math\n",
        "from dataclasses import dataclass\n",
        "from typing import Optional, Tuple, Dict, List\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import requests, certifi\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "\n",
        "# -----------------------------\n",
        "# Configuration\n",
        "# -----------------------------\n",
        "@dataclass\n",
        "class Config:\n",
        "    url: str = (\n",
        "        \"https://raw.githubusercontent.com/bredeespelid/\"\n",
        "        \"Data_MasterOppgave/refs/heads/main/Variables/All_Variables/variables_daily.csv\"\n",
        "    )\n",
        "    q_freq: str = \"Q-DEC\"      # quarterly evaluation\n",
        "    min_hist_days: int = 400   # more history for stable GB with many predictors\n",
        "    max_lags: int = 20         # number of daily lags for each predictor\n",
        "    max_horizon: int = 128     # must exceed longest quarter (~92 days)\n",
        "\n",
        "    # Gradient Boosting hyperparameters\n",
        "    n_estimators: int = 1800\n",
        "    learning_rate: float = 0.03\n",
        "    max_depth: int = 3\n",
        "    subsample: float = 0.8\n",
        "    min_samples_leaf: int = 2\n",
        "    random_state: int = 42\n",
        "\n",
        "    retries: int = 3\n",
        "    timeout: int = 60\n",
        "    verbose: bool = True\n",
        "    fig_png: str = \"GB_Q_daily_panel_pastcov.png\"\n",
        "    fig_pdf: str = \"GB_Q_daily_panel_pastcov.pdf\"\n",
        "\n",
        "CFG = Config()\n",
        "\n",
        "TARGET_SERIES = \"EUR_NOK\"\n",
        "PANEL_SERIES = [\n",
        "    \"EUR_NOK\",\n",
        "    \"Brent\",\n",
        "    \"VIX\",\n",
        "    \"StoxEurope\",\n",
        "    \"SP500\",\n",
        "    \"OSEBX\",\n",
        "    \"OBX_Energy\",\n",
        "]\n",
        "MACRO_COLS = [\"Q\", \"d_pi\", \"dI_t\"]\n",
        "\n",
        "ALL_PREDICTORS = PANEL_SERIES + MACRO_COLS  # all used as lagged predictors\n",
        "\n",
        "# -----------------------------\n",
        "# Download helper\n",
        "# -----------------------------\n",
        "def download_csv_text(url: str, retries: int, timeout: int) -> str:\n",
        "    \"\"\"Download CSV with simple retry/backoff.\"\"\"\n",
        "    last_err = None\n",
        "    for k in range(1, retries + 1):\n",
        "        try:\n",
        "            r = requests.get(url, timeout=timeout, verify=certifi.where())\n",
        "            r.raise_for_status()\n",
        "            return r.text\n",
        "        except Exception as e:\n",
        "            last_err = e\n",
        "            if k < retries:\n",
        "                wait = 1.5 * k\n",
        "                print(f\"[warning] Download failed (try {k}/{retries}): {e}. Retrying in {wait:.1f}s ...\")\n",
        "                time.sleep(wait)\n",
        "    raise RuntimeError(f\"Download failed: {last_err}\")\n",
        "\n",
        "# -----------------------------\n",
        "# Data loading: daily wide DF + EUR_NOK business-day series\n",
        "# -----------------------------\n",
        "def load_series(url: str) -> Tuple[pd.Series, pd.DataFrame]:\n",
        "    \"\"\"\n",
        "    Load daily CSV. Expected columns:\n",
        "      Date, EUR_NOK, Q, d_pi, dI_t, Brent, VIX, StoxEurope, SP500, OSEBX, OBX_Energy\n",
        "\n",
        "    Returns:\n",
        "      S_b  : EUR_NOK on business days (B) with ffill (for cuts and quarterly ground truth)\n",
        "      DF_d : daily (D) wide DataFrame with PANEL_SERIES + MACRO_COLS\n",
        "             calendar days, forward-filled\n",
        "    \"\"\"\n",
        "    text = download_csv_text(url, CFG.retries, CFG.timeout)\n",
        "    raw = pd.read_csv(io.StringIO(text))\n",
        "\n",
        "    required_cols = {\"Date\"} | set(ALL_PREDICTORS)\n",
        "    missing = required_cols - set(raw.columns)\n",
        "    if missing:\n",
        "        raise ValueError(f\"Missing columns in CSV: {missing}. Got: {list(raw.columns)}\")\n",
        "\n",
        "    df = (\n",
        "        raw[list(required_cols)]\n",
        "        .rename(columns={\"Date\": \"DATE\"})\n",
        "        .assign(DATE=lambda x: pd.to_datetime(x[\"DATE\"], errors=\"coerce\"))\n",
        "        .dropna(subset=[\"DATE\", TARGET_SERIES])\n",
        "        .sort_values(\"DATE\")\n",
        "        .set_index(\"DATE\")\n",
        "    )\n",
        "\n",
        "    # Ensure numeric types\n",
        "    for col in ALL_PREDICTORS:\n",
        "        df[col] = pd.to_numeric(df[col], errors=\"coerce\")\n",
        "    df = df.dropna(subset=[TARGET_SERIES])\n",
        "\n",
        "    # Business-day EUR_NOK (truth/aggregation base)\n",
        "    S_b = df[TARGET_SERIES].asfreq(\"B\").ffill().astype(float)\n",
        "    S_b.name = TARGET_SERIES\n",
        "\n",
        "    # Daily wide DF_d (calendar days, forward-filled)\n",
        "    full_idx = pd.date_range(df.index.min(), df.index.max(), freq=\"D\")\n",
        "    DF_d = df.reindex(full_idx).ffill()\n",
        "    DF_d.index.name = \"DATE\"\n",
        "\n",
        "    return S_b, DF_d\n",
        "\n",
        "def last_trading_day(S_b: pd.Series, start: pd.Timestamp, end: pd.Timestamp) -> Optional[pd.Timestamp]:\n",
        "    \"\"\"Return the last business day in [start, end].\"\"\"\n",
        "    sl = S_b.loc[start:end]\n",
        "    return sl.index[-1] if not sl.empty else None\n",
        "\n",
        "# -----------------------------\n",
        "# Feature engineering: multivariate lag matrix\n",
        "# -----------------------------\n",
        "def make_lag_matrix(\n",
        "    df_hist: pd.DataFrame,\n",
        "    predictors: List[str],\n",
        "    max_lags: int\n",
        ") -> Tuple[np.ndarray, np.ndarray, List[str]]:\n",
        "    \"\"\"\n",
        "    Build X, y for one-step ahead daily forecasting of EUR_NOK.\n",
        "\n",
        "    For each t:\n",
        "      X_t = stacked lags of all predictors (past-only):\n",
        "        [pred1_{t-1..t-L}, pred2_{t-1..t-L}, ...]\n",
        "      y_t = EUR_NOK_t\n",
        "    \"\"\"\n",
        "    work = df_hist[predictors].copy()\n",
        "    lag_cols: List[str] = []\n",
        "\n",
        "    for var in predictors:\n",
        "        for k in range(1, max_lags + 1):\n",
        "            name = f\"{var}_lag{k}\"\n",
        "            work[name] = work[var].shift(k)\n",
        "            lag_cols.append(name)\n",
        "\n",
        "    work = work.dropna()\n",
        "    X = work[lag_cols].values\n",
        "    y = work[TARGET_SERIES].values\n",
        "    return X, y, lag_cols\n",
        "\n",
        "# -----------------------------\n",
        "# Gradient Boosting one-step model\n",
        "# -----------------------------\n",
        "def fit_gb_one_step(df_hist_daily: pd.DataFrame) -> Tuple[GradientBoostingRegressor, List[str]]:\n",
        "    \"\"\"Fit GB for one-step daily prediction using lags of panel + macros.\"\"\"\n",
        "    X, y, lag_cols = make_lag_matrix(df_hist_daily, ALL_PREDICTORS, CFG.max_lags)\n",
        "\n",
        "    model = GradientBoostingRegressor(\n",
        "        n_estimators=CFG.n_estimators,\n",
        "        learning_rate=CFG.learning_rate,\n",
        "        max_depth=CFG.max_depth,\n",
        "        subsample=CFG.subsample,\n",
        "        min_samples_leaf=CFG.min_samples_leaf,\n",
        "        random_state=CFG.random_state,\n",
        "    )\n",
        "    model.fit(X, y)\n",
        "    return model, lag_cols\n",
        "\n",
        "def recursive_daily_forecast(\n",
        "    model: GradientBoostingRegressor,\n",
        "    df_hist_daily: pd.DataFrame,\n",
        "    H: int,\n",
        ") -> pd.Series:\n",
        "    \"\"\"\n",
        "    Produce H daily forecasts recursively.\n",
        "\n",
        "    Anti-leakage rule:\n",
        "      - Panel series and macros are treated as past-only covariates.\n",
        "      - During recursion all non-target predictors are frozen at their last observed level.\n",
        "    \"\"\"\n",
        "    hist = df_hist_daily[ALL_PREDICTORS].copy()\n",
        "    last_vals = hist.iloc[-1].to_dict()  # frozen predictors snapshot\n",
        "\n",
        "    preds = []\n",
        "    for _ in range(H):\n",
        "        if len(hist) < CFG.max_lags:\n",
        "            raise ValueError(\"Not enough history for lag features.\")\n",
        "\n",
        "        row_feats = []\n",
        "        for var in ALL_PREDICTORS:\n",
        "            lags = hist[var].iloc[-CFG.max_lags:][::-1].values\n",
        "            row_feats.extend(lags.tolist())\n",
        "\n",
        "        x = np.array(row_feats, dtype=float).reshape(1, -1)\n",
        "        yhat = float(model.predict(x)[0])\n",
        "        preds.append(yhat)\n",
        "\n",
        "        new_row = last_vals.copy()\n",
        "        new_row[TARGET_SERIES] = yhat  # update only target\n",
        "        new_idx = hist.index[-1] + pd.Timedelta(days=1)\n",
        "\n",
        "        hist = pd.concat([hist, pd.DataFrame([new_row], index=[new_idx])])\n",
        "\n",
        "    return pd.Series(preds)\n",
        "\n",
        "# -----------------------------\n",
        "# Quarterly walk-forward using GB + panel/macros (past-only)\n",
        "# -----------------------------\n",
        "def walk_forward_gb_quarterly_panel_pastcov(S_b: pd.Series, DF_d: pd.DataFrame) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    For each calendar quarter q:\n",
        "      - cut at last business day of previous quarter\n",
        "      - fit GB on daily history up to cut (EUR_NOK + panel + macros, lagged)\n",
        "      - recursively forecast full next quarter at daily frequency\n",
        "      - aggregate to business-day quarterly mean and compare to truth\n",
        "    \"\"\"\n",
        "    first_q = pd.Period(S_b.index.min(), freq=CFG.q_freq)\n",
        "    last_q  = pd.Period(S_b.index.max(), freq=CFG.q_freq)\n",
        "    quarters = pd.period_range(first_q, last_q, freq=CFG.q_freq)\n",
        "\n",
        "    rows: Dict = {}\n",
        "    dropped: Dict[str, str] = {}\n",
        "\n",
        "    for q in quarters:\n",
        "        prev_q = q - 1\n",
        "        q_start, q_end = q.start_time, q.end_time\n",
        "        prev_start, prev_end = prev_q.start_time, prev_q.end_time\n",
        "\n",
        "        cut = last_trading_day(S_b, prev_start, prev_end)\n",
        "        if cut is None:\n",
        "            dropped[str(q)] = \"no_cut_in_prev_quarter\"\n",
        "            continue\n",
        "\n",
        "        hist_df = DF_d.loc[:cut]\n",
        "        if hist_df.shape[0] < CFG.min_hist_days:\n",
        "            dropped[str(q)] = f\"hist<{CFG.min_hist_days}\"\n",
        "            continue\n",
        "\n",
        "        # Business days inside target quarter\n",
        "        idx_q_b = S_b.index[(S_b.index >= q_start) & (S_b.index <= q_end)]\n",
        "        if idx_q_b.size < 1:\n",
        "            dropped[str(q)] = \"no_bdays_in_quarter\"\n",
        "            continue\n",
        "        y_true = float(S_b.loc[idx_q_b].mean())\n",
        "\n",
        "        # Horizon = full calendar quarter length\n",
        "        H = (q_end.date() - q_start.date()).days + 1\n",
        "        if H <= 0 or H > CFG.max_horizon:\n",
        "            dropped[str(q)] = f\"horizon_invalid(H={H})\"\n",
        "            continue\n",
        "\n",
        "        model, _ = fit_gb_one_step(hist_df)\n",
        "        pf = recursive_daily_forecast(model, hist_df, H)\n",
        "\n",
        "        f_idx = pd.date_range(cut + pd.Timedelta(days=1), periods=H, freq=\"D\")\n",
        "        pred_daily = pd.Series(pf.values, index=f_idx, name=\"point\")\n",
        "\n",
        "        pred_b = pred_daily.reindex(idx_q_b, method=None)\n",
        "        if pred_b.isna().all():\n",
        "            dropped[str(q)] = \"no_overlap_pred_B_days\"\n",
        "            continue\n",
        "        y_pred = float(pred_b.dropna().mean())\n",
        "\n",
        "        rows[str(q)] = {\"quarter\": q, \"cut\": cut, \"y_true\": y_true, \"y_pred\": y_pred}\n",
        "\n",
        "    df = pd.DataFrame.from_dict(rows, orient=\"index\")\n",
        "    if not df.empty:\n",
        "        df = df.set_index(\"quarter\").sort_index()\n",
        "\n",
        "    if CFG.verbose and dropped:\n",
        "        miss = [str(q) for q in quarters if q not in df.index]\n",
        "        if miss:\n",
        "            print(\"\\nDropped quarters and reasons:\")\n",
        "            for qq in miss:\n",
        "                print(f\"  {qq}: {dropped.get(qq, 'unknown')}\")\n",
        "    return df\n",
        "\n",
        "# -----------------------------\n",
        "# Evaluation (level + direction)\n",
        "# -----------------------------\n",
        "def evaluate(eval_df: pd.DataFrame) -> pd.DataFrame:\n",
        "    df = eval_df.copy()\n",
        "    df[\"err\"] = df[\"y_true\"] - df[\"y_pred\"]\n",
        "    core = df.dropna(subset=[\"y_true\", \"y_pred\"]).copy()\n",
        "\n",
        "    n_obs = int(len(core))\n",
        "    rmse = float(np.sqrt(np.mean(np.square(core[\"err\"])))) if n_obs else np.nan\n",
        "    mae  = float(mean_absolute_error(core[\"y_true\"], core[\"y_pred\"])) if n_obs else np.nan\n",
        "\n",
        "    core[\"y_prev\"] = core[\"y_true\"].shift(1)\n",
        "    mask = core[\"y_prev\"].notna()\n",
        "    dir_true = np.sign(core.loc[mask, \"y_true\"] - core.loc[mask, \"y_prev\"])\n",
        "    dir_pred = np.sign(core.loc[mask, \"y_pred\"] - core.loc[mask, \"y_prev\"])\n",
        "    hits = int((dir_true.values == dir_pred.values).sum())\n",
        "    total = int(mask.sum())\n",
        "    hit_rate = (hits / total) if total else np.nan\n",
        "\n",
        "    print(\"\\n=== Model performance (quarterly mean, EUR/NOK – GB panel + past macro covariates) ===\")\n",
        "    print(f\"Observations: {n_obs}\")\n",
        "    print(f\"RMSE (level): {rmse:.6f}\")\n",
        "    print(f\"MAE  (level): {mae:.6f}\")\n",
        "    if total:\n",
        "        print(f\"Directional accuracy: {hits}/{total} ({hit_rate*100:.1f}%)\")\n",
        "\n",
        "    return core\n",
        "\n",
        "# -----------------------------\n",
        "# Diebold–Mariano (vs Random Walk)\n",
        "# -----------------------------\n",
        "def _normal_cdf(z: float) -> float:\n",
        "    return 0.5 * (1.0 + math.erf(z / math.sqrt(2.0)))\n",
        "\n",
        "def dm_test(y_true: pd.Series, y_model: pd.Series, y_rw: pd.Series, h: int = 1, loss: str = \"mse\") -> Tuple[float, float]:\n",
        "    df = pd.concat({\"y\": y_true, \"m\": y_model, \"rw\": y_rw}, axis=1).dropna()\n",
        "    if df.empty or len(df) < 5:\n",
        "        return float(\"nan\"), float(\"nan\")\n",
        "\n",
        "    e_m = df[\"y\"] - df[\"m\"]\n",
        "    e_r = df[\"y\"] - df[\"rw\"]\n",
        "    d = np.abs(e_m) - np.abs(e_r) if loss.lower() == \"mae\" else (e_m**2) - (e_r**2)\n",
        "\n",
        "    N = int(len(d))\n",
        "    d_mean = float(d.mean())\n",
        "    gamma0 = float(np.var(d, ddof=1)) if N > 1 else 0.0\n",
        "    var_bar = gamma0 / N\n",
        "\n",
        "    if h > 1 and N > 2:\n",
        "        for k in range(1, min(h - 1, N - 1) + 1):\n",
        "            w_k = 1.0 - k / h\n",
        "            cov_k = float(np.cov(d[k:], d[:-k], ddof=1)[0, 1])\n",
        "            var_bar += 2.0 * w_k * cov_k / N\n",
        "\n",
        "    if var_bar <= 0 or not np.isfinite(var_bar):\n",
        "        return float(\"nan\"), float(\"nan\")\n",
        "\n",
        "    dm_stat = d_mean / math.sqrt(var_bar)\n",
        "    p_val = 2.0 * (1.0 - _normal_cdf(abs(dm_stat)))\n",
        "    return dm_stat, p_val\n",
        "\n",
        "def dm_against_random_walk(eval_df: pd.DataFrame, loss: str = \"mse\", h: int = 1) -> None:\n",
        "    df = eval_df.copy()\n",
        "    df[\"rw_pred\"] = df[\"y_true\"].shift(1)\n",
        "    dm_stat, p_val = dm_test(df[\"y_true\"], df[\"y_pred\"], df[\"rw_pred\"], h=h, loss=loss)\n",
        "    print(\"\\n=== Diebold–Mariano vs Random Walk (GB panel setup, quarterly) ===\")\n",
        "    print(f\"Loss: {loss.upper()} | horizon h={h}\")\n",
        "    print(f\"DM-statistic: {dm_stat:.4f}\" if np.isfinite(dm_stat) else \"DM-statistic: nan\")\n",
        "    print(f\"p-value     : {p_val:.4f}\" if np.isfinite(p_val) else \"p-value     : nan\")\n",
        "\n",
        "# -----------------------------\n",
        "# Plot (no bands)\n",
        "# -----------------------------\n",
        "def plot_quarterly_simple(eval_df: pd.DataFrame, png_path: str, pdf_path: str):\n",
        "    if eval_df.empty:\n",
        "        print(\"Nothing to plot.\")\n",
        "        return\n",
        "\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    x = eval_df.index.to_timestamp() if isinstance(eval_df.index, pd.PeriodIndex) else eval_df.index\n",
        "\n",
        "    plt.plot(x, eval_df[\"y_true\"], color=\"black\", label=\"Actual (quarterly mean, B-days)\")\n",
        "    plt.plot(x, eval_df[\"y_pred\"], color=\"tab:blue\", linestyle=\"--\",\n",
        "             label=\"Forecast (Gradient Boosting, panel + past macro covariates)\")\n",
        "\n",
        "    plt.title(\"Gradient Boosting Forecast vs Actual (Quarterly Mean, EUR/NOK – panel setup)\")\n",
        "    plt.xlabel(\"Quarter\")\n",
        "    plt.ylabel(\"EUR/NOK level\")\n",
        "    plt.legend()\n",
        "    plt.grid(True, alpha=0.3)\n",
        "    plt.tight_layout()\n",
        "\n",
        "    plt.savefig(png_path, dpi=300, bbox_inches=\"tight\")\n",
        "    plt.savefig(pdf_path, bbox_inches=\"tight\")\n",
        "    plt.show()\n",
        "    print(f\"Saved: {png_path}\")\n",
        "    print(f\"Saved: {pdf_path}\")\n",
        "\n",
        "# -----------------------------\n",
        "# Main\n",
        "# -----------------------------\n",
        "def main():\n",
        "    S_b, DF_d = load_series(CFG.url)\n",
        "    if CFG.verbose:\n",
        "        print(f\"Data (B): {S_b.index.min().date()} → {S_b.index.max().date()} | n={len(S_b)}\")\n",
        "        print(f\"Data (D): {DF_d.index.min().date()} → {DF_d.index.max().date()} | n={len(DF_d)}\")\n",
        "        print(f\"Columns (DF_d): {list(DF_d.columns)}\")\n",
        "\n",
        "    df_eval = walk_forward_gb_quarterly_panel_pastcov(S_b, DF_d)\n",
        "    eval_df = evaluate(df_eval)\n",
        "\n",
        "    dm_against_random_walk(eval_df, loss=\"mse\", h=1)\n",
        "\n",
        "    plot_quarterly_simple(eval_df, CFG.fig_png, CFG.fig_pdf)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "id": "ywyZ7413Ty_0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}